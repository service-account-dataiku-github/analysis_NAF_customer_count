{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-env_clc",
      "display_name": "Python (env env_clc)",
      "language": "python"
    },
    "associatedRecipe": "compute_CALCULATED_CARD_DRAW_DOWNS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1665686179578
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1665686179578,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "Daniel.Vandermeer"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 37,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\nimport pickle\nfrom dateutil.relativedelta import relativedelta\nimport gc\nfrom re import finditer\n\n## Find DD DU\nfrom helper import preprocess_data\nfrom patterns import find_drawdowns, find_drawups\n\n## MATCHING\nimport name_matching\nfrom name_matching import name_match\nimport transaction_matching\nfrom transaction_matching import transaction_match\n\n## CONSOLIDATION\nfrom consolidation import combine_matches, consolidate_matches, find_attritions, find_new_accounts, get_attrition_status, get_new_account_status"
      ],
      "outputs": []
    },
    {
      "execution_count": 38,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "start_date \u003d dataiku.get_custom_variables()[\u0027start_date\u0027]\nend_date \u003d dataiku.get_custom_variables()[\u0027end_date\u0027]\n\nconsistency \u003d int(dataiku.get_custom_variables()[\u0027consistency\u0027])\ndrawdown_period_average \u003d int(dataiku.get_custom_variables()[\u0027drawdown_period_average\u0027])\ndrawdown \u003d int(dataiku.get_custom_variables()[\u0027drawdown\u0027])\ndrawdown_fwd_check \u003d int(dataiku.get_custom_variables()[\u0027drawdown_fwd_check\u0027])\ndrawdown_lookback_period \u003d int(dataiku.get_custom_variables()[\u0027drawdown_lookback_period\u0027])\ndrawup_lookfwd_period \u003d int(dataiku.get_custom_variables()[\u0027drawup_lookfwd_period\u0027])\nstatistics_period \u003d int(dataiku.get_custom_variables()[\u0027statistics_period\u0027])\ninactive_period \u003d int(dataiku.get_custom_variables()[\u0027inactive_period\u0027])\n\n## MATCHING VARIABLES\nmonth_diff_h \u003d int(dataiku.get_custom_variables()[\u0027month_diff_h\u0027])\nmonth_diff_l \u003d int(dataiku.get_custom_variables()[\u0027month_diff_l\u0027])\nsd_mul \u003d int(dataiku.get_custom_variables()[\u0027sd_mul\u0027])\nmax_city_distance \u003d int(dataiku.get_custom_variables()[\u0027max_city_distance\u0027])\nthreshold_score_step1 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step1\u0027])\nthreshold_score_step2 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step2\u0027])\n\n## RUN TYPE\nrun \u003d dataiku.get_custom_variables()[\u0027run_type\u0027]"
      ],
      "outputs": []
    },
    {
      "execution_count": 39,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def date_tz_naive(pd_s):\n    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))"
      ],
      "outputs": []
    },
    {
      "execution_count": 40,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nNAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED \u003d dataiku.Dataset(\"NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED\")\nNAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 42,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df\n\nprint(len(df_v))\ndf_v[\u0027REVENUE_DATE\u0027] \u003d df_v.REVENUE_MONTH.astype(str) + \"/01/\" + df_v.REVENUE_YEAR.astype(str)\ndf_v[\u0027REVENUE_DATE\u0027] \u003d date_tz_naive(df_v[\u0027REVENUE_DATE\u0027])\nprint(len(df_v))\n\ndf_v \u003d df_v[[\u0027CUSTOMER\u0027,\u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]]\n\ndf_cust \u003d  df_v.groupby(by\u003d[\"CUSTOMER\",\"REVENUE_DATE\"]).sum().reset_index()\ndf_cust.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "21965\n21965\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "  CUSTOMER REVENUE_DATE  ACTIVE_CARD_COUNT\n0     3GPP   2020-09-01               16.0\n1     3GPP   2020-10-01               22.0\n2     3GPP   2020-11-01               19.0\n3     3GPP   2020-12-01               27.0\n4     3GPP   2021-01-01               25.0",
            "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eCUSTOMER\u003c/th\u003e\n      \u003cth\u003eREVENUE_DATE\u003c/th\u003e\n      \u003cth\u003eACTIVE_CARD_COUNT\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e3GPP\u003c/td\u003e\n      \u003ctd\u003e2020-09-01\u003c/td\u003e\n      \u003ctd\u003e16.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e3GPP\u003c/td\u003e\n      \u003ctd\u003e2020-10-01\u003c/td\u003e\n      \u003ctd\u003e22.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e3GPP\u003c/td\u003e\n      \u003ctd\u003e2020-11-01\u003c/td\u003e\n      \u003ctd\u003e19.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e3GPP\u003c/td\u003e\n      \u003ctd\u003e2020-12-01\u003c/td\u003e\n      \u003ctd\u003e27.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e3GPP\u003c/td\u003e\n      \u003ctd\u003e2021-01-01\u003c/td\u003e\n      \u003ctd\u003e25.0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 43,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(len(df_v))\ndf_v \u003d df_v[df_v[\u0027REVENUE_DATE\u0027].between(pd.to_datetime(start_date), pd.to_datetime(end_date))].copy()\ndf_v \u003d df_v.dropna(subset\u003d[\u0027CUSTOMER\u0027])\nprint(len(df_v))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "21965\n21434\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 44,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v[\u0027REVENUE_DATE\u0027] \u003d pd.to_datetime(df_v[\u0027REVENUE_DATE\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 45,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v.sort_values([\u0027REVENUE_DATE\u0027], inplace\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 47,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "          CUSTOMER REVENUE_DATE  ACTIVE_CARD_COUNT\n0    GENERAL MILLS   2019-01-01             1398.0\n297      VISTAWALL   2019-01-01                1.0\n296       VOLVO CE   2019-01-01                0.0\n295   BAYER (3M33)   2019-01-01             1748.0\n294    CARGILL INC   2019-01-01              203.0",
            "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eCUSTOMER\u003c/th\u003e\n      \u003cth\u003eREVENUE_DATE\u003c/th\u003e\n      \u003cth\u003eACTIVE_CARD_COUNT\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003eGENERAL MILLS\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e1398.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e297\u003c/th\u003e\n      \u003ctd\u003eVISTAWALL\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e1.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e296\u003c/th\u003e\n      \u003ctd\u003eVOLVO CE\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e0.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e295\u003c/th\u003e\n      \u003ctd\u003eBAYER (3M33)\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e1748.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e294\u003c/th\u003e\n      \u003ctd\u003eCARGILL INC\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e203.0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 48,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "seen_accounts \u003d df_v[df_v[\u0027ACTIVE_CARD_COUNT\u0027] \u003e 0].groupby([\u0027CUSTOMER\u0027], as_index\u003dFalse)[[\u0027REVENUE_DATE\u0027]].first()\nseen_accounts[\u0027FIRST_DATE\u0027] \u003d seen_accounts[\u0027REVENUE_DATE\u0027] - pd.DateOffset(months\u003d1)"
      ],
      "outputs": []
    },
    {
      "execution_count": 49,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v.REVENUE_DATE.value_counts(dropna\u003dFalse)\nprint(len(df_v))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "21434\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 50,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom dateutil.relativedelta import relativedelta\nfrom helper import *"
      ],
      "outputs": []
    },
    {
      "execution_count": 51,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df \u003d df_v\nperiod_end_date \u003d end_date\nmatch_type \u003d \u0027program_flip\u0027\nperiod_start_date\u003dNone\nsplit\u003dNone"
      ],
      "outputs": []
    },
    {
      "execution_count": 53,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "drawdown \u003d (100 - drawdown)/100\ndrawdown_fwd_check /\u003d 100\n\ninactive_date_start \u003d pd.to_datetime(period_end_date) + relativedelta(months\u003d-inactive_period)\n\ndf \u003d df[df[\u0027REVENUE_DATE\u0027] \u003c\u003d period_end_date].copy()\n\nif period_start_date:\n    period_start_date \u003d pd.to_datetime(period_start_date)\n    df \u003d df[df[\u0027REVENUE_DATE\u0027] \u003e\u003d period_start_date].copy()\n\nall_account_ids \u003d list(df[\u0027CUSTOMER\u0027].unique())\n\nif not split:\n    split\u003d1\n\nall_account_ids_n \u003d list(split_list(all_account_ids, split))\n\ndrop_df \u003d pd.DataFrame()"
      ],
      "outputs": []
    },
    {
      "execution_count": 64,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_consistent_cust(df, consecutive\u003d3):\n    \u0027\u0027\u0027returns a list of customers who are consistent for 3 (default value) months\u0027\u0027\u0027\n    \n    ## Needs only these columns [\u0027customer_account_name\u0027, \u0027revenue_month\u0027, \u0027purchase_gallons_qty\u0027]\n    \n    df \u003d df[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]].copy()\n    df.sort_values(by\u003d[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n    \n    z \u003d (df.groupby([\u0027CUSTOMER\u0027])[\u0027REVENUE_DATE\u0027].diff(1)/np.timedelta64(1, \u0027M\u0027))\n    z \u003d z.round(0)\n    z \u003d (z \u003d\u003d 1).astype(\u0027int\u0027)\n    df[\u0027CUST_CONS\u0027] \u003d (z * (z.groupby((z !\u003d z.shift()).cumsum()).cumcount() + 2))\n    cust_cons \u003d df.groupby(\u0027CUSTOMER\u0027)[\u0027CUST_CONS\u0027].max()\n    \n    return list(cust_cons[cust_cons\u003e\u003dconsecutive].index)\n\ndef add_padding_func(df, padding\u003d12, last_date\u003dNone):\n    \u0027\u0027\u0027\n    Fills all the zeros in between for intermittent data and also fills the trailing data with \n    12 zeros or till the last date whichever is earlier\n    \u0027\u0027\u0027\n    \n    cols \u003d [\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027]\n    \n    common_cols \u003d set(df.columns).intersection(set(cols))\n    \n    profile \u003d df[common_cols].drop_duplicates()\n\n    vol \u003d df[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]].copy()\n    vol \u003d vol.groupby([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])[[\u0027ACTIVE_CARD_COUNT\u0027]].sum().reset_index()\n    vol.reset_index(drop\u003dTrue, inplace\u003dTrue)\n\n    vol.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n    vol.reset_index(drop\u003dTrue, inplace\u003dTrue)\n\n    last_rev_date \u003d vol.groupby([\u0027CUSTOMER\u0027])[[\u0027REVENUE_DATE\u0027]].last()\n    last_rev_date \u003d last_rev_date[last_rev_date[\u0027REVENUE_DATE\u0027] \u003c pd.to_datetime(last_date)]\n    last_rev_date[\u0027REVENUE_DATE\u0027] \u003d last_rev_date[\u0027REVENUE_DATE\u0027] + pd.DateOffset(months\u003dpadding)\n    last_rev_date[\u0027LAST_DATE\u0027] \u003d pd.to_datetime(last_date)\n    last_rev_date[\u0027REVENUE_DATE\u0027] \u003d last_rev_date[[\u0027REVENUE_DATE\u0027,\u0027LAST_DATE\u0027]].min(axis\u003d1)\n    last_rev_date.drop([\u0027LAST_DATE\u0027], axis\u003d1, inplace\u003dTrue)\n    last_rev_date.reset_index(inplace\u003dTrue)\n    vol \u003d pd.concat([vol, last_rev_date], ignore_index\u003dTrue)\n    vol.fillna(0, inplace\u003dTrue)\n    vol \u003d (vol.set_index(\u0027REVENUE_DATE\u0027).groupby(\u0027CUSTOMER\u0027).resample(\u0027MS\u0027).asfreq()\n                  .drop([\u0027CUSTOMER\u0027], 1).reset_index())\n    vol.fillna(0, inplace\u003dTrue)\n    df \u003d vol.merge(profile, how\u003d\u0027left\u0027, on \u003d [\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])\n    df.fillna(method\u003d\u0027ffill\u0027, inplace\u003dTrue)\n\n    return df\n\ndef find_average_func(dd_find, n\u003d12):\n   \n    dd_find.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n    dd_find2 \u003d dd_find.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], ascending\u003d[True, False]).reset_index(drop\u003dTrue)\n\n    dd_find.reset_index(drop\u003dTrue, inplace\u003dTrue)\n    dd_find[\u0027LAST_N_MONTHS_AVG\u0027] \u003d dd_find.groupby([\u0027CUSTOMER\u0027])[\u0027ACTIVE_CARD_COUNT\u0027]\\\n                                        .rolling(n, min_periods\u003d1).mean().reset_index(drop\u003dTrue)\n    dd_find2[\u0027NEXT_N_MONTHS_AVG\u0027] \u003d dd_find2.groupby([\u0027CUSTOMER\u0027])[\u0027ACTIVE_CARD_COUNT\u0027]\\\n                                        .rolling(n, min_periods\u003d1).mean().reset_index(drop\u003dTrue)\n\n    dd_find[\u0027LAST_N_MONTHS_AVG\u0027] \u003d dd_find.groupby(\u0027CUSTOMER\u0027)[\u0027LAST_N_MONTHS_AVG\u0027].shift(1)\n    dd_find2[\u0027NEXT_N_MONTHS_AVG\u0027] \u003d dd_find2.groupby(\u0027CUSTOMER\u0027)[\u0027NEXT_N_MONTHS_AVG\u0027].shift(1)\n\n    dd_find \u003d dd_find.merge(dd_find2[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027NEXT_N_MONTHS_AVG\u0027]], \n                on\u003d[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])\n\n    return dd_find\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 69,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for sublist in tqdm(all_account_ids_n):\n\n    dd_find \u003d df[df[\u0027CUSTOMER\u0027].isin(sublist)].copy()\n    \n    consistent_customers_dd \u003d find_consistent_cust(dd_find, consecutive\u003dconsistency)\n    if len(consistent_customers_dd) \u003d\u003d 0:\n        continue\n        \n    dd_find \u003d dd_find[dd_find[\u0027CUSTOMER\u0027].isin(consistent_customers_dd)].copy()\n    dd_find \u003d add_padding_func(dd_find, padding\u003dstatistics_period, last_date\u003dperiod_end_date)\n    dd_find \u003d find_average_func(dd_find, n\u003dstatistics_period)\n    \n    dd_find[\u0027DD_INDICATOR\u0027] \u003d np.where(((drawdown*(dd_find[\u0027LAST_N_MONTHS_AVG\u0027].round(3)) \u003e\n                                     dd_find[\u0027ACTIVE_CARD_COUNT\u0027].round(3)) \u0026\n                                    (dd_find[\u0027NEXT_N_MONTHS_AVG\u0027].round(3) \u003c\n                                     drawdown_fwd_check*dd_find[\u0027LAST_N_MONTHS_AVG\u0027].round(3))),\n                                   True, False)\n    \n    ## Find the first drawdown and also the list of customers\n    pflip_dd \u003d dd_find[dd_find[\u0027DD_INDICATOR\u0027] \u003d\u003d True].copy()\n    pflip_dd.drop_duplicates(\u0027CUSTOMER\u0027, inplace\u003dTrue)\n    first_drop_idx \u003d pflip_dd.index\n    pflip_dd_customers \u003d list(dd_find[\u0027CUSTOMER\u0027].unique())\n    first_drop \u003d dd_find.iloc[first_drop_idx]\n    \n    ## Identify the lookback period\n    first_drop \u003d first_drop[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027]].copy()\n    first_drop \u003d first_drop[first_drop[\u0027REVENUE_DATE\u0027] \u003c\u003d inactive_date_start].copy()\n    first_drop[\u0027START_DATE\u0027]  \u003d first_drop[\u0027REVENUE_DATE\u0027] - pd.DateOffset(months\u003ddrawdown_lookback_period)\n    first_drop.rename(columns \u003d {\u0027REVENUE_DATE\u0027:\u0027DD_DATE\u0027}, inplace\u003dTrue)\n    dd_find_df \u003d dd_find[dd_find[\u0027CUSTOMER\u0027].isin(pflip_dd_customers)]\n    dd_find_df \u003d dd_find_df.merge(first_drop, on\u003d[\u0027CUSTOMER\u0027])\n    dd_find_df \u003d dd_find_df[dd_find_df[\u0027REVENUE_DATE\u0027].between(dd_find_df[\u0027START_DATE\u0027],dd_find_df[\u0027DD_DATE\u0027])].copy()\n\n    ## Compute the sharpest fall from the lookback period\n    dd_find_df.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n    dd_find_df[\u0027DROP\u0027] \u003d dd_find_df.groupby([\u0027CUSTOMER_ACCOUNT_ID\u0027])[\u0027PURCHASE_GALLONS_QTY\u0027].diff(-1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 1/1 [00:02\u003c00:00,  2.15s/it]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\n#CALCULATED_CARD_DRAW_DOWNS_df \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df # For this sample code, simply copy input to output\n\n# Write recipe outputs\n#CALCULATED_CARD_DRAW_DOWNS \u003d dataiku.Dataset(\"CALCULATED_CARD_DRAW_DOWNS\")\n#CALCULATED_CARD_DRAW_DOWNS.write_with_schema(CALCULATED_CARD_DRAW_DOWNS_df)"
      ],
      "outputs": []
    }
  ]
}