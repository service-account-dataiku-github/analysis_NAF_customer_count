{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python in cpu-m-cpu-3-mem-4Gb (builtin env)",
      "language": "python",
      "name": "py-dku-containerized-venv--cpu-m-cpu-3-mem-4gb"
    },
    "associatedRecipe": "compute_CALCULATED_DRAW_DOWNS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1665593021198
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1665593021198,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "import pandas as pd, numpy as np\n",
        "from dataiku import pandasutils as pdu\n",
        "\n",
        "import pickle\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import gc\n",
        "from re import finditer\n",
        "\n",
        "## Find DD DU\n",
        "from helper import preprocess_data\n",
        "from patterns import find_drawdowns, find_drawups\n",
        "\n",
        "## MATCHING\n",
        "import name_matching\n",
        "from name_matching import name_match\n",
        "import transaction_matching\n",
        "from transaction_matching import transaction_match\n",
        "\n",
        "## CONSOLIDATION\n",
        "from consolidation import combine_matches, consolidate_matches, find_attritions, find_new_accounts, get_attrition_status, get_new_account_status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "start_date \u003d dataiku.get_custom_variables()[\u0027start_date\u0027]\n",
        "end_date \u003d dataiku.get_custom_variables()[\u0027end_date\u0027]\n",
        "\n",
        "consistency \u003d int(dataiku.get_custom_variables()[\u0027consistency\u0027])\n",
        "drawdown_period_average \u003d int(dataiku.get_custom_variables()[\u0027drawdown_period_average\u0027])\n",
        "drawdown \u003d int(dataiku.get_custom_variables()[\u0027drawdown\u0027])\n",
        "drawdown_fwd_check \u003d int(dataiku.get_custom_variables()[\u0027drawdown_fwd_check\u0027])\n",
        "drawdown_lookback_period \u003d int(dataiku.get_custom_variables()[\u0027drawdown_lookback_period\u0027])\n",
        "drawup_lookfwd_period \u003d int(dataiku.get_custom_variables()[\u0027drawup_lookfwd_period\u0027])\n",
        "statistics_period \u003d int(dataiku.get_custom_variables()[\u0027statistics_period\u0027])\n",
        "inactive_period \u003d int(dataiku.get_custom_variables()[\u0027inactive_period\u0027])\n",
        "\n",
        "## MATCHING VARIABLES\n",
        "month_diff_h \u003d int(dataiku.get_custom_variables()[\u0027month_diff_h\u0027])\n",
        "month_diff_l \u003d int(dataiku.get_custom_variables()[\u0027month_diff_l\u0027])\n",
        "sd_mul \u003d int(dataiku.get_custom_variables()[\u0027sd_mul\u0027])\n",
        "max_city_distance \u003d int(dataiku.get_custom_variables()[\u0027max_city_distance\u0027])\n",
        "threshold_score_step1 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step1\u0027])\n",
        "threshold_score_step2 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step2\u0027])\n",
        "\n",
        "## RUN TYPE\n",
        "run \u003d dataiku.get_custom_variables()[\u0027run_type\u0027]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "def date_tz_naive(pd_s):\n",
        "    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Read recipe inputs\n",
        "NAFCUSTOMER_C360_ACCOUNTS \u003d dataiku.Dataset(\"NAFCUSTOMER_C360_ACCOUNTS\")\n",
        "NAFCUSTOMER_C360_ACCOUNTS_df \u003d NAFCUSTOMER_C360_ACCOUNTS.get_dataframe()\n",
        "print(len(NAFCUSTOMER_C360_ACCOUNTS_df))\n",
        "\n",
        "NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED \u003d dataiku.Dataset(\"NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED\")\n",
        "NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED.get_dataframe()\n",
        "print(len(NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df\n",
        "\n",
        "print(len(df_v))\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d df_v.REVENUE_MONTH.astype(str) + \"/01/\" + df_v.REVENUE_YEAR.astype(str)\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d date_tz_naive(df_v[\u0027REVENUE_DATE\u0027])\n",
        "print(len(df_v))\n",
        "df_v.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "print(len(df_v))\n",
        "df_v \u003d df_v[df_v[\u0027REVENUE_DATE\u0027].between(pd.to_datetime(start_date), pd.to_datetime(end_date))].copy()\n",
        "df_v \u003d df_v.dropna(subset\u003d[\u0027CUSTOMER_ACCOUNT_ID\u0027])\n",
        "df_v \u003d df_v[df_v[\u0027CUSTOMER_SOURCE_SYSTEM_CODE\u0027].isin([\u0027TANDEM\u0027, \u0027SIEBEL\u0027])]\n",
        "print(len(df_v))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027] \u003d df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027].astype(\u0027int64\u0027)\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d pd.to_datetime(df_v[\u0027REVENUE_DATE\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "states \u003d list(df_v[\u0027ACCOUNT_STATE\u0027].unique())\n",
        "states_dict \u003d {s:s.upper() for s in states}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "states_dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Compute recipe outputs from inputs\n",
        "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
        "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
        "\n",
        "\n",
        "\n",
        "CALCULATED_DRAW_DOWNS_df \u003d NAFCUSTOMER_C360_ACCOUNTS_df # For this sample code, simply copy input to output\n",
        "\n",
        "\n",
        "# Write recipe outputs\n",
        "CALCULATED_DRAW_DOWNS \u003d dataiku.Dataset(\"CALCULATED_DRAW_DOWNS\")\n",
        "CALCULATED_DRAW_DOWNS.write_with_schema(CALCULATED_DRAW_DOWNS_df)"
      ]
    }
  ]
}