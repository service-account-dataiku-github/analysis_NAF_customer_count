{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python in cpu-m-cpu-3-mem-4Gb (env env_clc)",
      "language": "python",
      "name": "py-dku-containerized-venv-env_clc-cpu-m-cpu-3-mem-4gb"
    },
    "associatedRecipe": "compute_CALCULATED_DRAW_UPS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1665655849923
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1665655849923,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "import pandas as pd, numpy as np\n",
        "from dataiku import pandasutils as pdu\n",
        "\n",
        "import pickle\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import gc\n",
        "from re import finditer\n",
        "\n",
        "## Find DD DU\n",
        "from helper import preprocess_data\n",
        "from patterns import find_drawdowns, find_drawups\n",
        "\n",
        "## MATCHING\n",
        "import name_matching\n",
        "from name_matching import name_match\n",
        "import transaction_matching\n",
        "from transaction_matching import transaction_match\n",
        "\n",
        "## CONSOLIDATION\n",
        "from consolidation import combine_matches, consolidate_matches, find_attritions, find_new_accounts, get_attrition_status, get_new_account_status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "start_date \u003d dataiku.get_custom_variables()[\u0027start_date\u0027]\n",
        "end_date \u003d dataiku.get_custom_variables()[\u0027end_date\u0027]\n",
        "\n",
        "consistency \u003d int(dataiku.get_custom_variables()[\u0027consistency\u0027])\n",
        "drawdown_period_average \u003d int(dataiku.get_custom_variables()[\u0027drawdown_period_average\u0027])\n",
        "drawdown \u003d int(dataiku.get_custom_variables()[\u0027drawdown\u0027])\n",
        "drawdown_fwd_check \u003d int(dataiku.get_custom_variables()[\u0027drawdown_fwd_check\u0027])\n",
        "drawdown_lookback_period \u003d int(dataiku.get_custom_variables()[\u0027drawdown_lookback_period\u0027])\n",
        "drawup_lookfwd_period \u003d int(dataiku.get_custom_variables()[\u0027drawup_lookfwd_period\u0027])\n",
        "statistics_period \u003d int(dataiku.get_custom_variables()[\u0027statistics_period\u0027])\n",
        "inactive_period \u003d int(dataiku.get_custom_variables()[\u0027inactive_period\u0027])\n",
        "\n",
        "## MATCHING VARIABLES\n",
        "month_diff_h \u003d int(dataiku.get_custom_variables()[\u0027month_diff_h\u0027])\n",
        "month_diff_l \u003d int(dataiku.get_custom_variables()[\u0027month_diff_l\u0027])\n",
        "sd_mul \u003d int(dataiku.get_custom_variables()[\u0027sd_mul\u0027])\n",
        "max_city_distance \u003d int(dataiku.get_custom_variables()[\u0027max_city_distance\u0027])\n",
        "threshold_score_step1 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step1\u0027])\n",
        "threshold_score_step2 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step2\u0027])\n",
        "\n",
        "## RUN TYPE\n",
        "run \u003d dataiku.get_custom_variables()[\u0027run_type\u0027]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Read recipe inputs\n",
        "NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED \u003d dataiku.Dataset(\"NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED\")\n",
        "NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED.get_dataframe()\n",
        "\n",
        "print(len(NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df), \"rows\")\n",
        "\n",
        "print(len(NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df.CUSTOMER_ACCOUNT_ID.unique()), \"accounts\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df\n",
        "\n",
        "print(len(df_v))\n",
        "df_v.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "def date_tz_naive(pd_s):\n",
        "    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "print(len(df_v))\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d df_v.REVENUE_MONTH.astype(str) + \"/01/\" + df_v.REVENUE_YEAR.astype(str)\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d date_tz_naive(df_v[\u0027REVENUE_DATE\u0027])\n",
        "print(len(df_v))\n",
        "df_v.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "print(len(df_v))\n",
        "df_v \u003d df_v[df_v[\u0027REVENUE_DATE\u0027].between(pd.to_datetime(start_date), pd.to_datetime(end_date))].copy()\n",
        "df_v \u003d df_v.dropna(subset\u003d[\u0027CUSTOMER_ACCOUNT_ID\u0027])\n",
        "df_v \u003d df_v[df_v[\u0027CUSTOMER_SOURCE_SYSTEM_CODE\u0027].isin([\u0027TANDEM\u0027, \u0027SIEBEL\u0027])]\n",
        "print(len(df_v))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027] \u003d df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027].astype(\u0027int64\u0027)\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d pd.to_datetime(df_v[\u0027REVENUE_DATE\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from helper import *\n",
        "\n",
        "def split_list(lst, n):\n",
        "    \u0027\u0027\u0027\n",
        "    Splits a list into almost equal n parts\n",
        "    \u0027\u0027\u0027\n",
        "    k, m \u003d divmod(len(lst), n)\n",
        "    return [lst[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n)]\n",
        "\n",
        "match_type \u003d \"program_flip\"\n",
        "period_start_date \u003d start_date\n",
        "period_end_date \u003d None\n",
        "drawup_window \u003d drawup_lookfwd_period\n",
        "statistics_period \u003d statistics_period\n",
        "split \u003d None\n",
        "\n",
        "if match_type \u003d\u003d \u0027conversion\u0027:\n",
        "    df_v \u003d df_v[df_v[\u0027CUSTOMER_SOURCE_SYSTEM_CODE\u0027] \u003d\u003d \u0027SIEBEL\u0027].copy()\n",
        "\n",
        "period_start_date \u003d pd.to_datetime(period_start_date)\n",
        "df_v \u003d df_v[df_v[\u0027REVENUE_DATE\u0027] \u003e\u003d period_start_date].copy()\n",
        "\n",
        "if period_end_date:\n",
        "    period_end_date \u003d pd.to_datetime(period_end_date)\n",
        "    df_v \u003d df_v[df_v[\u0027revenue_date\u0027] \u003c\u003d period_end_date].copy()\n",
        "\n",
        "all_account_ids \u003d list(df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027].unique())\n",
        "\n",
        "if not split:\n",
        "    split\u003d1\n",
        "\n",
        "all_account_ids_n \u003d list(split_list(all_account_ids, split))\n",
        "\n",
        "rise_df \u003d pd.DataFrame()\n",
        "\n",
        "for sublist in tqdm(all_account_ids_n):\n",
        "\n",
        "    du_find \u003d df_v[df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027].isin(sublist)].copy()\n",
        "\n",
        "    ## Filter Non-Zero Records and find the first non zero transaction date\n",
        "    du_find \u003d du_find[du_find[\u0027PURCHASE_GALLONS_QTY\u0027] \u003e 0]\n",
        "\n",
        "    du_find.sort_values([\u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n",
        "\n",
        "    du_agg \u003d du_find.groupby([\u0027CUSTOMER_ACCOUNT_ID\u0027,\n",
        "                      \u0027CUSTOMER_ACCOUNT_NAME\u0027,\n",
        "                      \u0027CUSTOMER\u0027,\n",
        "                      \u0027CUSTOMER_SOURCE_SYSTEM_CODE\u0027,\n",
        "                      \u0027ACCOUNT_CITY\u0027,\n",
        "                      \u0027ACCOUNT_STATE\u0027,\n",
        "                      \u0027CUSTOMER_BUSINESS_PROGRAM_NAME\u0027], as_index\u003dFalse)[[\u0027REVENUE_DATE\u0027]].min()\n",
        "\n",
        "    du_agg[\u0027DU_INDICATOR\u0027] \u003d np.where((du_agg[\u0027REVENUE_DATE\u0027] \u003e period_start_date), True, False)\n",
        "    du_agg.rename(columns\u003d{\u0027REVENUE_DATE\u0027:\u0027DU_DATE\u0027}, inplace\u003dTrue)\n",
        "    du_agg[\u0027DU_DATE\u0027] -\u003d pd.DateOffset(months\u003d1)\n",
        "    du_agg \u003d du_agg[du_agg[\u0027DU_INDICATOR\u0027] \u003d\u003d True].drop_duplicates([\u0027CUSTOMER_ACCOUNT_ID\u0027])\n",
        "\n",
        "    ## list of customers who are drawing up\n",
        "    du_customers \u003d list(du_agg[\u0027CUSTOMER_ACCOUNT_ID\u0027])\n",
        "\n",
        "    if len(du_customers) \u003d\u003d 0:\n",
        "        continue\n",
        "\n",
        "    du_find \u003d du_find[du_find[\u0027CUSTOMER_ACCOUNT_ID\u0027].isin(du_customers)].copy()\n",
        "\n",
        "    du_find \u003d du_find.groupby(\u0027CUSTOMER_ACCOUNT_ID\u0027).apply(lambda group: group.iloc[:-1, 1:]).reset_index()\n",
        "    du_find.drop(\u0027level_1\u0027, axis\u003d1, inplace\u003dTrue)\n",
        "\n",
        "    du_find \u003d du_find.merge(du_agg, left_on\u003d[\u0027CUSTOMER_ACCOUNT_ID\u0027], right_on\u003d[\u0027CUSTOMER_ACCOUNT_ID\u0027])\n",
        "\n",
        "    du_find[\u0027DU_AVG_START\u0027] \u003d du_find[\u0027DU_DATE\u0027]  + pd.DateOffset(months\u003ddrawup_window)\n",
        "    du_find[\u0027DU_AVG_END\u0027] \u003d du_find[\u0027DU_DATE\u0027]  + pd.DateOffset(months\u003ddrawup_window+statistics_period-1)\n",
        "\n",
        "    du_find_12 \u003d du_find[du_find[\u0027REVENUE_DATE\u0027].between(du_find[\u0027DU_AVG_START\u0027], du_find[\u0027DU_AVG_END\u0027])].copy()\n",
        "\n",
        "    du_stat \u003d du_find_12.groupby([\u0027CUSTOMER_ACCOUNT_ID\u0027], as_index\u003dFalse).agg({\u0027PURCHASE_GALLONS_QTY\u0027:[\u0027mean\u0027,\u0027std\u0027]})\n",
        "\n",
        "    du_stat.columns \u003d [\u0027CUSTOMER_ACCOUNT_ID\u0027, \u0027mean_du\u0027,\u0027std_du\u0027]\n",
        "\n",
        "    rise_df_ \u003d du_agg.merge(du_stat, left_on\u003d\u0027CUSTOMER_ACCOUNT_ID\u0027, right_on\u003d\u0027CUSTOMER_ACCOUNT_ID\u0027, how\u003d\u0027left\u0027)\n",
        "\n",
        "    rise_df \u003d pd.concat([rise_df, rise_df_], ignore_index\u003dTrue)\n",
        "\n",
        "rise_df.head()\n",
        "\n",
        "rise_df.rename(columns\u003d{\u0027customer_account_id\u0027:\u0027customer_account_id_du\u0027,\n",
        "                    \u0027customer_account_name\u0027: \u0027customer_account_name_du\u0027,\n",
        "                    \u0027customer_name\u0027: \u0027customer_name_du\u0027}, inplace\u003dTrue)\n",
        "\n",
        "rise_df.rename(columns\u003d{\u0027mean_du\u0027:\u0027DU_MEAN\u0027,\n",
        "                       \u0027std_du\u0027:\u0027DU_STD\u0027}, inplace\u003dTrue)\n",
        "\n",
        "print(len(rise_df))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "rise_df \u003d rise_df[[\u0027CUSTOMER_ACCOUNT_ID\u0027,\u0027DU_DATE\u0027]]\n",
        "rise_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "CALCULATED_DRAW_UPS_df \u003d rise_df\n",
        "\n",
        "# Write recipe outputs\n",
        "CALCULATED_DRAW_UPS \u003d dataiku.Dataset(\"CALCULATED_DRAW_UPS\")\n",
        "CALCULATED_DRAW_UPS.write_with_schema(CALCULATED_DRAW_UPS_df)"
      ]
    }
  ]
}