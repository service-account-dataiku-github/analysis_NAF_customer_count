{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python in cpu-m-cpu-3-mem-4Gb (env env_clc)",
      "language": "python",
      "name": "py-dku-containerized-venv-env_clc-cpu-m-cpu-3-mem-4gb"
    },
    "associatedRecipe": "compute_CALCULATED_DRAW_DOWNS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1667062120007
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1667062120007,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "import pandas as pd, numpy as np\n",
        "from dataiku import pandasutils as pdu\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from helper import *\n",
        "import time\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "import pandas as pd, numpy as np\n",
        "from dataiku import pandasutils as pdu\n",
        "\n",
        "import pickle\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import gc\n",
        "from re import finditer\n",
        "\n",
        "## Find DD DU\n",
        "from helper import preprocess_data\n",
        "from patterns import find_drawdowns, find_drawups\n",
        "\n",
        "## MATCHING\n",
        "import name_matching\n",
        "from name_matching import name_match\n",
        "import transaction_matching\n",
        "from transaction_matching import transaction_match\n",
        "\n",
        "## CONSOLIDATION\n",
        "from consolidation import combine_matches, consolidate_matches, find_attritions, find_new_accounts, get_attrition_status, get_new_account_status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "start_date \u003d dataiku.get_custom_variables()[\u0027start_date\u0027]\n",
        "end_date \u003d dataiku.get_custom_variables()[\u0027end_date\u0027]\n",
        "\n",
        "consistency \u003d int(dataiku.get_custom_variables()[\u0027consistency\u0027])\n",
        "drawdown_period_average \u003d int(dataiku.get_custom_variables()[\u0027drawdown_period_average\u0027])\n",
        "drawdown \u003d int(dataiku.get_custom_variables()[\u0027drawdown\u0027])\n",
        "drawdown_fwd_check \u003d int(dataiku.get_custom_variables()[\u0027drawdown_fwd_check\u0027])\n",
        "drawdown_lookback_period \u003d int(dataiku.get_custom_variables()[\u0027drawdown_lookback_period\u0027])\n",
        "drawup_lookfwd_period \u003d int(dataiku.get_custom_variables()[\u0027drawup_lookfwd_period\u0027])\n",
        "statistics_period \u003d int(dataiku.get_custom_variables()[\u0027statistics_period\u0027])\n",
        "inactive_period \u003d int(dataiku.get_custom_variables()[\u0027inactive_period\u0027])\n",
        "\n",
        "## MATCHING VARIABLES\n",
        "month_diff_h \u003d int(dataiku.get_custom_variables()[\u0027month_diff_h\u0027])\n",
        "month_diff_l \u003d int(dataiku.get_custom_variables()[\u0027month_diff_l\u0027])\n",
        "sd_mul \u003d int(dataiku.get_custom_variables()[\u0027sd_mul\u0027])\n",
        "max_city_distance \u003d int(dataiku.get_custom_variables()[\u0027max_city_distance\u0027])\n",
        "threshold_score_step1 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step1\u0027])\n",
        "threshold_score_step2 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step2\u0027])\n",
        "\n",
        "## RUN TYPE\n",
        "run \u003d dataiku.get_custom_variables()[\u0027run_type\u0027]\n",
        "\n",
        "print(\"start_date\", start_date)\n",
        "print(\"end_date\", end_date)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Read recipe inputs\n",
        "NAFCUSTOMER_ACTIVE_CARDS_FULL \u003d dataiku.Dataset(\"NAFCUSTOMER_ACTIVE_CARDS_FULL\")\n",
        "NAFCUSTOMER_ACTIVE_CARDS_FULL_df \u003d NAFCUSTOMER_ACTIVE_CARDS_FULL.get_dataframe()\n",
        "print(len(NAFCUSTOMER_ACTIVE_CARDS_FULL_df))\n",
        "NAFCUSTOMER_ACTIVE_CARDS_FULL_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "def date_tz_naive(pd_s):\n",
        "    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "customer_list_full \u003d NAFCUSTOMER_ACTIVE_CARDS_FULL_df.CUSTOMER.unique()\n",
        "print(len(customer_list_full))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "def find_consistent_cust(df, consecutive\u003d3):\n",
        "    \u0027\u0027\u0027returns a list of customers who are consistent for 3 (default value) months\u0027\u0027\u0027\n",
        "\n",
        "    ## Needs only these columns [\u0027customer_account_name\u0027, \u0027revenue_month\u0027, \u0027purchase_gallons_qty\u0027]\n",
        "\n",
        "    df \u003d df[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]].copy()\n",
        "    df.sort_values(by\u003d[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n",
        "\n",
        "    z \u003d (df.groupby([\u0027CUSTOMER\u0027])[\u0027REVENUE_DATE\u0027].diff(1)/np.timedelta64(1, \u0027M\u0027))\n",
        "    z \u003d z.round(0)\n",
        "    z \u003d (z \u003d\u003d 1).astype(\u0027int\u0027)\n",
        "    df[\u0027CUST_CONS\u0027] \u003d (z * (z.groupby((z !\u003d z.shift()).cumsum()).cumcount() + 2))\n",
        "    cust_cons \u003d df.groupby(\u0027CUSTOMER\u0027)[\u0027CUST_CONS\u0027].max()\n",
        "\n",
        "    return list(cust_cons[cust_cons\u003e\u003dconsecutive].index)\n",
        "\n",
        "def add_padding_func(df, padding\u003d12, last_date\u003dNone):\n",
        "    \u0027\u0027\u0027\n",
        "    Fills all the zeros in between for intermittent data and also fills the trailing data with\n",
        "    12 zeros or till the last date whichever is earlier\n",
        "    \u0027\u0027\u0027\n",
        "\n",
        "    cols \u003d [\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027]\n",
        "\n",
        "    common_cols \u003d set(df.columns).intersection(set(cols))\n",
        "\n",
        "    profile \u003d df[common_cols].drop_duplicates()\n",
        "\n",
        "    vol \u003d df[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]].copy()\n",
        "    vol \u003d vol.groupby([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])[[\u0027ACTIVE_CARD_COUNT\u0027]].sum().reset_index()\n",
        "    vol.reset_index(drop\u003dTrue, inplace\u003dTrue)\n",
        "\n",
        "    vol.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n",
        "    vol.reset_index(drop\u003dTrue, inplace\u003dTrue)\n",
        "\n",
        "    last_rev_date \u003d vol.groupby([\u0027CUSTOMER\u0027])[[\u0027REVENUE_DATE\u0027]].last()\n",
        "    last_rev_date \u003d last_rev_date[last_rev_date[\u0027REVENUE_DATE\u0027] \u003c pd.to_datetime(last_date)]\n",
        "    last_rev_date[\u0027REVENUE_DATE\u0027] \u003d last_rev_date[\u0027REVENUE_DATE\u0027] + pd.DateOffset(months\u003dpadding)\n",
        "    last_rev_date[\u0027LAST_DATE\u0027] \u003d pd.to_datetime(last_date)\n",
        "    last_rev_date[\u0027REVENUE_DATE\u0027] \u003d last_rev_date[[\u0027REVENUE_DATE\u0027,\u0027LAST_DATE\u0027]].min(axis\u003d1)\n",
        "    last_rev_date.drop([\u0027LAST_DATE\u0027], axis\u003d1, inplace\u003dTrue)\n",
        "    last_rev_date.reset_index(inplace\u003dTrue)\n",
        "    vol \u003d pd.concat([vol, last_rev_date], ignore_index\u003dTrue)\n",
        "    vol.fillna(0, inplace\u003dTrue)\n",
        "    vol \u003d (vol.set_index(\u0027REVENUE_DATE\u0027).groupby(\u0027CUSTOMER\u0027).resample(\u0027MS\u0027).asfreq()\n",
        "                  .drop([\u0027CUSTOMER\u0027], 1).reset_index())\n",
        "    vol.fillna(0, inplace\u003dTrue)\n",
        "    df \u003d vol.merge(profile, how\u003d\u0027left\u0027, on \u003d [\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])\n",
        "    df.fillna(method\u003d\u0027ffill\u0027, inplace\u003dTrue)\n",
        "\n",
        "    return df\n",
        "\n",
        "def find_average_func(dd_find, n\u003d12):\n",
        "\n",
        "    dd_find.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n",
        "    dd_find2 \u003d dd_find.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], ascending\u003d[True, False]).reset_index(drop\u003dTrue)\n",
        "\n",
        "    dd_find.reset_index(drop\u003dTrue, inplace\u003dTrue)\n",
        "    dd_find[\u0027LAST_N_MONTHS_AVG\u0027] \u003d dd_find.groupby([\u0027CUSTOMER\u0027])[\u0027ACTIVE_CARD_COUNT\u0027]\\\n",
        "                                        .rolling(n, min_periods\u003d1).mean().reset_index(drop\u003dTrue)\n",
        "    dd_find2[\u0027NEXT_N_MONTHS_AVG\u0027] \u003d dd_find2.groupby([\u0027CUSTOMER\u0027])[\u0027ACTIVE_CARD_COUNT\u0027]\\\n",
        "                                        .rolling(n, min_periods\u003d1).mean().reset_index(drop\u003dTrue)\n",
        "\n",
        "    dd_find[\u0027LAST_N_MONTHS_AVG\u0027] \u003d dd_find.groupby(\u0027CUSTOMER\u0027)[\u0027LAST_N_MONTHS_AVG\u0027].shift(1)\n",
        "    dd_find2[\u0027NEXT_N_MONTHS_AVG\u0027] \u003d dd_find2.groupby(\u0027CUSTOMER\u0027)[\u0027NEXT_N_MONTHS_AVG\u0027].shift(1)\n",
        "\n",
        "    dd_find \u003d dd_find.merge(dd_find2[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027NEXT_N_MONTHS_AVG\u0027]],\n",
        "                on\u003d[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])\n",
        "\n",
        "    return dd_find"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "page_size \u003d 50000\n",
        "idx \u003d 0\n",
        "current_page \u003d 0\n",
        "max_pages \u003d 0\n",
        "\n",
        "drop_df \u003d pd.DataFrame()\n",
        "t0 \u003d time.time()\n",
        "\n",
        "total_pages \u003d len(customer_list_full)/page_size\n",
        "\n",
        "while idx\u003clen(customer_list_full):\n",
        "\n",
        "    current_page+\u003d1\n",
        "    print(\"page\", current_page)\n",
        "\n",
        "    to_range \u003d idx+page_size\n",
        "    if to_range\u003elen(customer_list_full):\n",
        "        to_range \u003d len(customer_list_full)-1\n",
        "\n",
        "    current_set \u003d customer_list_full[idx:to_range]\n",
        "\n",
        "    #\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
        "\n",
        "    df_v \u003d NAFCUSTOMER_ACTIVE_CARDS_FULL_df[NAFCUSTOMER_ACTIVE_CARDS_FULL_df.CUSTOMER.isin(current_set)]\n",
        "    print(\"processing\", len(df_v.CUSTOMER.unique()), \"customers\")\n",
        "    print(len(df_v), \"data frame records\")\n",
        "\n",
        "    df_v[\u0027REVENUE_DATE\u0027] \u003d df_v.REVENUE_MONTH.astype(str) + \"/01/\" + df_v.REVENUE_YEAR.astype(str)\n",
        "    df_v[\u0027REVENUE_DATE\u0027] \u003d date_tz_naive(df_v[\u0027REVENUE_DATE\u0027])\n",
        "\n",
        "    df_v \u003d df_v[[\u0027CUSTOMER\u0027,\u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]]\n",
        "\n",
        "    df_v_max \u003d df_v[[\u0027CUSTOMER\u0027,\u0027ACTIVE_CARD_COUNT\u0027]]\n",
        "    df_max \u003d df_v_max.groupby(by\u003d[\"CUSTOMER\"]).max().reset_index()\n",
        "    df_max.columns \u003d [\u0027CUSTOMER\u0027, \u0027ACTIVE_CARD_MAX\u0027]\n",
        "\n",
        "    df_v.dropna(subset\u003d[\u0027CUSTOMER\u0027], inplace\u003dTrue)\n",
        "\n",
        "    df_v[\u0027REVENUE_DATE\u0027] \u003d pd.to_datetime(df_v[\u0027REVENUE_DATE\u0027])\n",
        "    df_v.sort_values([\u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n",
        "\n",
        "    seen_accounts \u003d df_v[df_v[\u0027ACTIVE_CARD_COUNT\u0027] \u003e 0].groupby([\u0027CUSTOMER\u0027], as_index\u003dFalse)[[\u0027REVENUE_DATE\u0027]].first()\n",
        "    seen_accounts[\u0027FIRST_DATE\u0027] \u003d seen_accounts[\u0027REVENUE_DATE\u0027] - pd.DateOffset(months\u003d1)\n",
        "\n",
        "    df \u003d df_v\n",
        "    period_end_date \u003d end_date\n",
        "    match_type \u003d \u0027program_flip\u0027\n",
        "    period_start_date\u003dNone\n",
        "    split\u003dNone\n",
        "\n",
        "    drawdown \u003d (100 - drawdown)/100\n",
        "    drawdown_fwd_check /\u003d 100\n",
        "\n",
        "    inactive_date_start \u003d pd.to_datetime(period_end_date) + relativedelta(months\u003d-inactive_period)\n",
        "\n",
        "    df \u003d df[df[\u0027REVENUE_DATE\u0027] \u003c\u003d period_end_date].copy()\n",
        "\n",
        "    if period_start_date:\n",
        "        period_start_date \u003d pd.to_datetime(period_start_date)\n",
        "        df \u003d df[df[\u0027REVENUE_DATE\u0027] \u003e\u003d period_start_date].copy()\n",
        "\n",
        "    all_customer_names \u003d list(df[\u0027CUSTOMER\u0027].unique())\n",
        "\n",
        "    dd_find \u003d df[df[\u0027CUSTOMER\u0027].isin(all_customer_names)].copy()\n",
        "\n",
        "    consistent_customers_dd \u003d find_consistent_cust(dd_find, consecutive\u003dconsistency)\n",
        "    if len(consistent_customers_dd) \u003d\u003d 0:\n",
        "        continue\n",
        "\n",
        "    dd_find \u003d dd_find[dd_find[\u0027CUSTOMER\u0027].isin(consistent_customers_dd)].copy()\n",
        "    dd_find \u003d add_padding_func(dd_find, padding\u003dstatistics_period, last_date\u003dperiod_end_date)\n",
        "    dd_find \u003d find_average_func(dd_find, n\u003dstatistics_period)\n",
        "\n",
        "    dd_find[\u0027DD_INDICATOR\u0027] \u003d np.where(((drawdown*(dd_find[\u0027LAST_N_MONTHS_AVG\u0027].round(3)) \u003e\n",
        "                                     dd_find[\u0027ACTIVE_CARD_COUNT\u0027].round(3)) \u0026\n",
        "                                    (dd_find[\u0027NEXT_N_MONTHS_AVG\u0027].round(3) \u003c\n",
        "                                     drawdown_fwd_check*dd_find[\u0027LAST_N_MONTHS_AVG\u0027].round(3))),\n",
        "                                   True, False)\n",
        "\n",
        "    ## Find the first drawdown and also the list of customers\n",
        "    pflip_dd \u003d dd_find[dd_find[\u0027DD_INDICATOR\u0027] \u003d\u003d True].copy()\n",
        "    pflip_dd.drop_duplicates(\u0027CUSTOMER\u0027, inplace\u003dTrue)\n",
        "    first_drop_idx \u003d pflip_dd.index\n",
        "    pflip_dd_customers \u003d list(dd_find[\u0027CUSTOMER\u0027].unique())\n",
        "    first_drop \u003d dd_find.iloc[first_drop_idx]\n",
        "\n",
        "    ## Identify the lookback period\n",
        "    first_drop \u003d first_drop[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027]].copy()\n",
        "    first_drop \u003d first_drop[first_drop[\u0027REVENUE_DATE\u0027] \u003c\u003d inactive_date_start].copy()\n",
        "    first_drop[\u0027START_DATE\u0027]  \u003d first_drop[\u0027REVENUE_DATE\u0027] - pd.DateOffset(months\u003ddrawdown_lookback_period)\n",
        "    first_drop.rename(columns \u003d {\u0027REVENUE_DATE\u0027:\u0027DD_DATE\u0027}, inplace\u003dTrue)\n",
        "    dd_find_df \u003d dd_find[dd_find[\u0027CUSTOMER\u0027].isin(pflip_dd_customers)]\n",
        "    dd_find_df \u003d dd_find_df.merge(first_drop, on\u003d[\u0027CUSTOMER\u0027])\n",
        "    dd_find_df \u003d dd_find_df[dd_find_df[\u0027REVENUE_DATE\u0027].between(dd_find_df[\u0027START_DATE\u0027],dd_find_df[\u0027DD_DATE\u0027])].copy()\n",
        "\n",
        "    ## Compute the sharpest fall from the lookback period\n",
        "    dd_find_df.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n",
        "    dd_find_df[\u0027DROP\u0027] \u003d dd_find_df.groupby([\u0027CUSTOMER\u0027])[\u0027ACTIVE_CARD_COUNT\u0027].diff(-1)\n",
        "\n",
        "    ## Find the corresponding period and remove duplicates in case of a similar values\n",
        "    drop_idx \u003d dd_find_df.groupby([\u0027CUSTOMER\u0027])[\u0027DROP\u0027].transform(max) \u003d\u003d dd_find_df[\u0027DROP\u0027]\n",
        "    drop_month_df \u003d dd_find_df[drop_idx].copy()\n",
        "    drop_month_df.drop_duplicates([\u0027CUSTOMER\u0027], inplace\u003dTrue)\n",
        "\n",
        "    ## remove the first record\n",
        "    dd_find \u003d dd_find.groupby(\u0027CUSTOMER\u0027).apply(lambda group: group.iloc[1:, 1:]).reset_index()\n",
        "    dd_find.drop(\u0027level_1\u0027, axis\u003d1, inplace\u003dTrue)\n",
        "\n",
        "    ## Find the time periods for calculating statistics (mean and standard deviation)\n",
        "    drop_month_df.rename(columns \u003d {\u0027REVENUE_DATE\u0027:\u0027DROP_DATE\u0027}, inplace\u003dTrue)\n",
        "    dd_find \u003d dd_find.merge(drop_month_df[[\u0027CUSTOMER\u0027, \u0027DROP_DATE\u0027]], on\u003d\u0027CUSTOMER\u0027)\n",
        "    dd_find[\u0027END_DATE\u0027] \u003d dd_find[\u0027DROP_DATE\u0027] - pd.DateOffset(months\u003d3)\n",
        "    dd_find[\u0027START_DATE\u0027] \u003d dd_find[\u0027END_DATE\u0027] - pd.DateOffset(months\u003dstatistics_period-1)\n",
        "    pflip_12_data \u003d dd_find[dd_find[\u0027REVENUE_DATE\u0027].between(dd_find[\u0027START_DATE\u0027], dd_find[\u0027END_DATE\u0027])].copy()\n",
        "\n",
        "    ## Calculate Mean and Standard Deviation\n",
        "    dd_stat \u003d pflip_12_data.groupby([\u0027CUSTOMER\u0027], as_index\u003dFalse).agg({\u0027ACTIVE_CARD_COUNT\u0027:[\u0027mean\u0027,\u0027std\u0027]})\n",
        "    dd_stat.columns \u003d [\u0027CUSTOMER_DD\u0027, \u0027MEAN_DD\u0027,\u0027STD_DD\u0027]\n",
        "    drop_month_df \u003d drop_month_df.merge(dd_stat,\n",
        "                                        left_on\u003d\u0027CUSTOMER\u0027,\n",
        "                                        right_on\u003d\u0027CUSTOMER_DD\u0027,\n",
        "                                        how\u003d\u0027left\u0027)\n",
        "\n",
        "    drop_month_df \u003d pd.merge(drop_month_df, df_max, on\u003d\u0027CUSTOMER\u0027, how\u003d\u0027left\u0027)\n",
        "    drop_month_df \u003d drop_month_df[[\u0027CUSTOMER\u0027,\u0027DROP_DATE\u0027,\u0027ACTIVE_CARD_MAX\u0027]]\n",
        "    drop_month_df.columns \u003d [\u0027CUSTOMER\u0027,\u0027DRAW_DOWN_DATE\u0027,\u0027ACTIVE_CARD_MAX\u0027]\n",
        "\n",
        "    print(len(drop_month_df), \"new drop records\")\n",
        "    drop_df \u003d pd.concat([drop_df, drop_month_df], ignore_index\u003dTrue)\n",
        "\n",
        "    print(len(drop_df), \"total drop records\")\n",
        "    print(\"saving to snowflake...\")\n",
        "    CALCULATED_DRAW_DOWNS_df \u003d drop_df\n",
        "    CALCULATED_DRAW_DOWNS \u003d dataiku.Dataset(\"CALCULATED_DRAW_DOWNS\")\n",
        "    CALCULATED_DRAW_DOWNS.write_with_schema(CALCULATED_DRAW_DOWNS_df)\n",
        "\n",
        "    pages_remaining \u003d total_pages-current_page\n",
        "\n",
        "    t1 \u003d time.time()\n",
        "    avg_duration \u003d (((t1-t0)/current_page)/60.0)\n",
        "    print(round(avg_duration,2), \"avg mins per iteration\")\n",
        "    print(round(pages_remaining,2), \"pages remaining\")\n",
        "    print(round(avg_duration*pages_remaining,2), \"estimated minutes remaining\")\n",
        "    print()\n",
        "\n",
        "    #\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
        "\n",
        "    idx+\u003dpage_size\n",
        "\n",
        "    if max_pages\u003e0:\n",
        "        if current_page\u003e\u003dmax_pages:\n",
        "            break;\n",
        "\n",
        "print(\"done\")"
      ]
    }
  ]
}