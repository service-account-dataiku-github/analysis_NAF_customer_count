{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-env_clc",
      "display_name": "Python (env env_clc)",
      "language": "python"
    },
    "associatedRecipe": "compute_MATCHES_1_TO_N_STAGING_V",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1667169923254
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1667169923254,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "Daniel.Vandermeer"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom difflib import SequenceMatcher\nimport Levenshtein\n\n# Read recipe inputs\nCALCULATED_DRAW_DOWNS \u003d dataiku.Dataset(\"CALCULATED_DRAW_DOWNS\")\nCALCULATED_DRAW_DOWNS_df \u003d CALCULATED_DRAW_DOWNS.get_dataframe()\n\nCALCULATED_DRAW_UPS \u003d dataiku.Dataset(\"CALCULATED_DRAW_UPS\")\nCALCULATED_DRAW_UPS_df \u003d CALCULATED_DRAW_UPS.get_dataframe()\n\nCOMMON_WORDS \u003d dataiku.Dataset(\"NAFCUSTOMER_COMMON_WORDS_IN_NAMES\")\nCOMMON_WORDS_df \u003d COMMON_WORDS.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def date_tz_naive(pd_s):\n    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))"
      ],
      "outputs": []
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# consider customers with the card threshold or more\n# set this too low and the running time will balloon\n\ncard_cut_off_threshold \u003d 2\n\ndf_down_full \u003d CALCULATED_DRAW_DOWNS_df[CALCULATED_DRAW_DOWNS_df.ACTIVE_CARD_MAX\u003ecard_cut_off_threshold].copy()\ndf_up_full \u003d CALCULATED_DRAW_UPS_df[CALCULATED_DRAW_UPS_df.ACTIVE_CARD_MAX\u003ecard_cut_off_threshold].copy()\n\ndf_down_full.DRAW_DOWN_DATE \u003d date_tz_naive(df_down_full[\u0027DRAW_DOWN_DATE\u0027])\ndf_up_full.DRAW_UP_DATE \u003d date_tz_naive(df_up_full[\u0027DRAW_UP_DATE\u0027])\n\ndf_up_full.dropna(subset\u003d[\u0027DRAW_UP_DATE\u0027], inplace\u003dTrue)\n\ndf_common \u003d COMMON_WORDS_df\n\ndf_down_full.sort_values([\u0027CUSTOMER\u0027], inplace\u003dTrue)\ndf_up_full.sort_values([\u0027CUSTOMER\u0027], inplace\u003dTrue)\ndf_common.sort_values([\u0027WORD\u0027], inplace\u003dTrue)\n\nprint(len(df_down_full), \"draw downs full\")\nprint(len(df_up_full), \"draw ups full\")\nprint(len(df_common), \"common words\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "74235 draw downs full\n162049 draw ups full\n2173 common words\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import string\n\n_common_words \u003d df_common.WORD.unique()\nprint(len(_common_words), \"screening against common words\")\n\nclass Draw_Down_Customer:\n\n    def __init__(self, name, draw_down_date, active_card_max):\n\n        self.CUSTOMER \u003d name\n        self.DRAW_DOWN_DATE \u003d draw_down_date\n        self.ACTIVE_CARD_MAX \u003d active_card_max\n\n        self.MATCHING_CUSTOMERS \u003d []\n        self.PERCENT_DIFFERENCE \u003d []\n        self.DAYS_DIFFERENCE \u003d []\n        self.DRAW_UP_DATE \u003d []\n\n        # remove punctuation\n        c_str \u003d name.translate(str.maketrans(\u0027\u0027, \u0027\u0027, string.punctuation))\n\n        f \u003d c_str.split()\n        self.WORD_LIST \u003d []\n        for w in f:\n            if w not in _common_words:\n                self.WORD_LIST.append(w)\n\n    def Match_Draw_Up_Customer(self, name, draw_up_date, active_card_max):\n\n        if (self.CUSTOMER \u003d\u003d name):\n            # exact match, already captured\n            return\n\n        c_str \u003d name.translate(str.maketrans(\u0027\u0027, \u0027\u0027, string.punctuation))\n\n        f \u003d c_str.split()\n\n        check_list \u003d []\n        for w in f:\n            if (w not in _common_words) and (len(w)\u003e1) and (not w.isnumeric()):\n                check_list.append(w)\n\n        percent_diff \u003d round((abs(self.ACTIVE_CARD_MAX - active_card_max) / ((self.ACTIVE_CARD_MAX+active_card_max)/2)),2)\n\n        #date_format \u003d \"%Y-%m-%d\"\n        #d1_date \u003d datetime.strptime(draw_up_date.astype(str), date_format)\n        #d2_date \u003d datetime.strptime(self.DRAW_DOWN_DATE.astype(str), date_format)\n\n        delta_between_drop_and_rise \u003d round(abs((draw_up_date-self.DRAW_DOWN_DATE).days)/30.,0)\n\n        for w_to_check in check_list:\n            for w in self.WORD_LIST:\n                if w_to_check\u003d\u003dw:\n\n                    if not name in(self.MATCHING_CUSTOMERS) and(delta_between_drop_and_rise\u003c\u003d4)and(percent_diff\u003c\u003d0.5) :\n                        self.MATCHING_CUSTOMERS.append(name)\n                        self.PERCENT_DIFFERENCE.append(percent_diff)\n                        self.DAYS_DIFFERENCE.append(delta_between_drop_and_rise)\n                        self.DRAW_UP_DATE.append(draw_up_date)\n                        break;"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "2173 screening against common words\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n\ndef do_save_log(_matching_process_log_time, _matching_process_log_event):\n\n    df_matching_log \u003d pd.DataFrame(_matching_process_log_time)\n    if len(df_matching_log)\u003e0:\n\n        df_matching_log.columns \u003d [\u0027LOG_TIME\u0027]\n        df_matching_log[\u0027LOG_EVENT\u0027] \u003d _matching_process_log_event\n\n        MATCHING_PROCESS_LOG_V_df \u003d df_matching_log\n        MATCHING_PROCESS_LOG_V \u003d dataiku.Dataset(\"MATCHING_PROCESS_LOG_V\")\n        MATCHING_PROCESS_LOG_V.write_with_schema(MATCHING_PROCESS_LOG_V_df)\n\n        print()\n\ndef do_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date):\n\n    df_matches \u003d pd.DataFrame(_direct_customer)\n    if len(df_matches)\u003e0:\n\n        print()\n        print(\"saving\", len(df_matches), \"1-1 matching records\")\n        print()\n\n        df_matches.columns \u003d [\u0027CUSTOMER\u0027]\n        df_matches[\"MATCH_CUSTOMER\"] \u003d _direct_match\n        df_matches[\"DRAW_UP_DATE\"] \u003d _direct_draw_up_date\n\n        MATCHES_1_TO_1_STAGING_V_df \u003d df_matches\n        MATCHES_1_TO_1_STAGING_V \u003d dataiku.Dataset(\"MATCHES_1_TO_1_STAGING_V\")\n        MATCHES_1_TO_1_STAGING_V.write_with_schema(MATCHES_1_TO_1_STAGING_V_df)\n\n        print()\n\ndef do_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates):\n\n    df_multiple_matches \u003d pd.DataFrame(_multiple_customer)\n\n    if len(df_multiple_matches)\u003e0:\n\n        print()\n        print(\"saving\", len(df_multiple_matches), \"1-n matching records\")\n        print()\n\n        df_multiple_matches.columns \u003d [\u0027CUSTOMER\u0027]\n        df_multiple_matches[\"MATCH_CUSTOMER\"] \u003d _multiple_matches\n        df_multiple_matches[\"DRAW_UP_DATE\"] \u003d _multiple_drop_dates\n\n        MATCHES_1_TO_N_STAGING_V_df \u003d df_multiple_matches\n        MATCHES_1_TO_N_STAGING_V \u003d dataiku.Dataset(\"MATCHES_1_TO_N_STAGING_V\")\n        MATCHES_1_TO_N_STAGING_V.write_with_schema(MATCHES_1_TO_N_STAGING_V_df)\n\n        print()"
      ],
      "outputs": []
    },
    {
      "execution_count": 6,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from datetime import timedelta\n\ndf_down \u003d df_down_full\ndf_up \u003d df_up_full\n\n_processed_customers \u003d []\nverbose \u003d False\n\n_matching_process_log_time \u003d []\n_matching_process_log_event \u003d []\n\n_direct_customer \u003d []\n_direct_match \u003d []\n_direct_draw_up_date \u003d []\n\n_multiple_customer \u003d []\n_multiple_matches \u003d []\n_multiple_drop_dates \u003d []\n\n_no_match_customer \u003d []\n\nsave_every_n \u003d 50\nto_save_counter \u003d 0\nprint_every_n \u003d 100\n\nprint(len(df_down), \"filtered down rows\")\nprint(len(df_up), \"filtered up rows\")\n\n_customers \u003d []\n\nt0 \u003d time.time()\n\nfor index, row in df_down.iterrows():\n\n    customer \u003d row[\u0027CUSTOMER\u0027]\n    draw_down_date \u003d row[\u0027DRAW_DOWN_DATE\u0027]\n    active_card_max \u003d row[\u0027ACTIVE_CARD_MAX\u0027]\n\n    c \u003d Draw_Down_Customer(customer, draw_down_date, active_card_max)\n\n    _customers.append(c)\n\nidx \u003d 0\n\n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\" processing range \" + str(len(_customers)) + \" Draw Down Customers\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "74235 filtered down rows\n162049 filtered up rows\n1 rows successfully written (oA1nqcSxze)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "idx\u003d0\nfor c in _customers:\n\n    idx+\u003d1\n\n    date_start \u003d pd.to_datetime(c.DRAW_DOWN_DATE) +timedelta(days\u003d-120)\n    date_end \u003d pd.to_datetime(c.DRAW_DOWN_DATE) +timedelta(days\u003d120)\n\n    card_delta \u003d c.ACTIVE_CARD_MAX * 0.5\n    card_start \u003d c.ACTIVE_CARD_MAX - card_delta\n    card_end \u003d c.ACTIVE_CARD_MAX + card_delta\n\n    df_up \u003d df_up_full[(df_up_full.ACTIVE_CARD_MAX\u003e\u003dcard_start)\u0026\n                   (df_up_full.ACTIVE_CARD_MAX\u003c\u003dcard_end)\u0026\n                    (df_up_full.DRAW_UP_DATE \u003e\u003d pd.to_datetime(date_start))\u0026\n                  (df_up_full.DRAW_UP_DATE \u003c\u003d pd.to_datetime(date_end))].copy()\n\n    df_up[\u0027distance\u0027] \u003d 0.0\n    df_up.distance \u003d df_up.apply(lambda x: Levenshtein.ratio(x[\u0027CUSTOMER\u0027],c.CUSTOMER),axis\u003d1)\n    df_up.dropna(subset\u003d[\u0027distance\u0027], inplace\u003dTrue)\n\n    df_up \u003d df_up[df_up.distance\u003e0.8]\n\n    for index_up, row_up in df_up.iterrows():\n\n        customer \u003d row_up[\u0027CUSTOMER\u0027]\n        draw_up_date \u003d row_up[\u0027DRAW_UP_DATE\u0027]\n        active_card_max \u003d row_up[\u0027ACTIVE_CARD_MAX\u0027]\n\n        c.Match_Draw_Up_Customer(customer, draw_up_date, active_card_max)\n\n    if len(c.MATCHING_CUSTOMERS)\u003d\u003d1:\n\n        if not c.CUSTOMER in (_processed_customers):\n\n            to_save_counter +\u003d 1\n\n            _direct_customer.append(c.CUSTOMER)\n            _processed_customers.append(c.CUSTOMER)\n            _direct_match.append(c.MATCHING_CUSTOMERS[0])\n            _processed_customers.append(c.MATCHING_CUSTOMERS[0])\n            _direct_draw_up_date.append(c.DRAW_UP_DATE[0])\n\n            if verbose:\n                print()\n                print(\"DIRECT\")\n                print(c.CUSTOMER, c.WORD_LIST)\n                print(c.MATCHING_CUSTOMERS)\n                print(c.PERCENT_DIFFERENCE)\n                print(c.DAYS_DIFFERENCE)\n                print(\"\u003d\u003d\u003d\u003d\u003d\")\n                print()\n\n    elif len(c.MATCHING_CUSTOMERS)\u003e1:\n\n        if not c.CUSTOMER in (_processed_customers):\n\n            to_save_counter +\u003d 1\n\n            _multiple_customer.append(c.CUSTOMER)\n            _processed_customers.append(c.CUSTOMER)\n            _multiple_matches.append(c.MATCHING_CUSTOMERS)\n            _multiple_drop_dates.append(c.DRAW_UP_DATE)\n\n        if verbose:\n            print()\n            print(\"MULTIPLE\")\n            print(c.CUSTOMER, c.WORD_LIST)\n            print(c.MATCHING_CUSTOMERS)\n            print(c.PERCENT_DIFFERENCE)\n            print(c.DAYS_DIFFERENCE)\n            print(\"\u003d\u003d\u003d\u003d\u003d\")\n            print()\n\n    else:\n\n        # could not find a match, remove it from future processing\n        _no_match_customer.append(c.CUSTOMER)\n        _processed_customers.append(c.CUSTOMER)\n\n    if to_save_counter\u003e\u003dsave_every_n:\n\n        _matching_process_log_time.append(str(pd.Timestamp.now()))\n        _matching_process_log_event.append(\"writing datasets to snowflake\")\n        do_save_log(_matching_process_log_time, _matching_process_log_event)\n\n        do_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date)\n        do_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates)\n\n        _matching_process_log_time.append(str(pd.Timestamp.now()))\n        _matching_process_log_event.append(\"saved \" + str(to_save_counter) + \" records to snowflake.\")\n        do_save_log(_matching_process_log_time, _matching_process_log_event)\n\n        to_save_counter \u003d 0\n\n    t1 \u003d time.time()\n\n    avg_duration \u003d (((t1-t0)/idx)/60.0)\n\n    if idx % print_every_n \u003d\u003d 0:\n        idx_remaining \u003d len(_customers)-idx\n        print(\"processing\", idx, \"current record:\", c.CUSTOMER, \",\", idx_remaining, \"remaining\")\n        print(round(avg_duration,2), \"avg mins per iteration\",  round((avg_duration*idx_remaining)/60,2), \"estimated hrs remaining\")\n        print(len(_direct_customer), \"direct match records\", len(_multiple_customer), \"multiple match records\", len(_no_match_customer), \"no match records\")\n        print()\n\n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\"writing datasets to snowflake\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)\n\ndo_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date)\ndo_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates)\n\n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\"saved \" + str(to_save_counter) + \" records to snowflake.\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "processing 100 current record: 1000198 SPM OIL  GAS INC V , 74135 remaining\n0.01 avg mins per iteration 7.59 estimated hrs remaining\n3 direct match records 0 multiple match records 97 no match records\n\nprocessing 200 current record: 1260 TESORO PETROLEUM , 74035 remaining\n0.0 avg mins per iteration 5.86 estimated hrs remaining\n4 direct match records 0 multiple match records 196 no match records\n\nprocessing 300 current record: 17634-HEATING \u0026 COOLING , 73935 remaining\n0.0 avg mins per iteration 5.25 estimated hrs remaining\n5 direct match records 0 multiple match records 295 no match records\n\nprocessing 400 current record: 18506-KRAFT OPERATIONS , 73835 remaining\n0.0 avg mins per iteration 4.45 estimated hrs remaining\n6 direct match records 0 multiple match records 394 no match records\n\nprocessing 500 current record: 2 MOMS  A MOP INC , 73735 remaining\n0.0 avg mins per iteration 4.47 estimated hrs remaining\n6 direct match records 0 multiple match records 494 no match records\n\nprocessing 600 current record: 2225252 ONTARIO INC , 73635 remaining\n0.0 avg mins per iteration 4.46 estimated hrs remaining\n7 direct match records 1 multiple match records 592 no match records\n\nprocessing 700 current record: 28 SKINCARE LLC , 73535 remaining\n0.0 avg mins per iteration 4.46 estimated hrs remaining\n10 direct match records 1 multiple match records 689 no match records\n\nprocessing 800 current record: 306317-CHARLEY \u0026 SONS INC , 73435 remaining\n0.0 avg mins per iteration 4.41 estimated hrs remaining\n11 direct match records 1 multiple match records 788 no match records\n\nprocessing 900 current record: 3586 VIRBAC CORPORATION , 73335 remaining\n0.0 avg mins per iteration 4.21 estimated hrs remaining\n11 direct match records 1 multiple match records 888 no match records\n\nprocessing 1000 current record: 4 SEASONAL SERVICES LLC , 73235 remaining\n0.0 avg mins per iteration 4.25 estimated hrs remaining\n13 direct match records 1 multiple match records 986 no match records\n\nprocessing 1100 current record: 4X INDUSTRIAL LLC , 73135 remaining\n0.0 avg mins per iteration 4.23 estimated hrs remaining\n14 direct match records 1 multiple match records 1085 no match records\n\nprocessing 1200 current record: 5H LOGISTICS LLC , 73035 remaining\n0.0 avg mins per iteration 4.2 estimated hrs remaining\n14 direct match records 1 multiple match records 1185 no match records\n\n",
          "name": "stdout"
        }
      ]
    }
  ]
}