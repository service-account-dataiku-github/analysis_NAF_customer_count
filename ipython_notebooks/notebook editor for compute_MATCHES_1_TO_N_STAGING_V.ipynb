{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-env_clc",
      "display_name": "Python (env env_clc)",
      "language": "python"
    },
    "associatedRecipe": "compute_MATCHES_1_TO_N_STAGING_V",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1667169923254
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1667169923254,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "Daniel.Vandermeer"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 15,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom difflib import SequenceMatcher\nimport Levenshtein\n\n# Read recipe inputs\nCALCULATED_DRAW_DOWNS \u003d dataiku.Dataset(\"CALCULATED_DRAW_DOWNS\")\nCALCULATED_DRAW_DOWNS_df \u003d CALCULATED_DRAW_DOWNS.get_dataframe()\n\nCALCULATED_DRAW_UPS \u003d dataiku.Dataset(\"CALCULATED_DRAW_UPS\")\nCALCULATED_DRAW_UPS_df \u003d CALCULATED_DRAW_UPS.get_dataframe()\n\nCOMMON_WORDS \u003d dataiku.Dataset(\"NAFCUSTOMER_COMMON_WORDS_IN_NAMES\")\nCOMMON_WORDS_df \u003d COMMON_WORDS.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 16,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def date_tz_naive(pd_s):\n    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))"
      ],
      "outputs": []
    },
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# consider customers with the card threshold or more\n# set this too low and the running time will balloon\n# recommend: 10 or higher\n\ncard_cut_off_threshold \u003d 5\n\ndf_down_full \u003d CALCULATED_DRAW_DOWNS_df[CALCULATED_DRAW_DOWNS_df.ACTIVE_CARD_MAX\u003ecard_cut_off_threshold].copy()\ndf_up_full \u003d CALCULATED_DRAW_UPS_df[CALCULATED_DRAW_UPS_df.ACTIVE_CARD_MAX\u003ecard_cut_off_threshold].copy()\n\ndf_down_full.DRAW_DOWN_DATE \u003d date_tz_naive(df_down_full[\u0027DRAW_DOWN_DATE\u0027])\ndf_up_full.DRAW_UP_DATE \u003d date_tz_naive(df_up_full[\u0027DRAW_UP_DATE\u0027])\n\ndf_up_full.dropna(subset\u003d[\u0027DRAW_UP_DATE\u0027], inplace\u003dTrue)\n\ndf_common \u003d COMMON_WORDS_df\n\ndf_down_full.sort_values([\u0027CUSTOMER\u0027], inplace\u003dTrue)\ndf_up_full.sort_values([\u0027CUSTOMER\u0027], inplace\u003dTrue)\ndf_common.sort_values([\u0027WORD\u0027], inplace\u003dTrue)\n\nprint(len(df_down_full), \"draw downs full\")\nprint(len(df_up_full), \"draw ups full\")\nprint(len(df_common), \"common words\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "34027 draw downs full\n72496 draw ups full\n2173 common words\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 18,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import string\n\n_common_words \u003d df_common.WORD.unique()\nprint(len(_common_words), \"screening against common words\")\n\nclass Draw_Down_Customer:\n\n    def __init__(self, name, draw_down_date, active_card_max):\n\n        self.CUSTOMER \u003d name\n        self.DRAW_DOWN_DATE \u003d draw_down_date\n        self.ACTIVE_CARD_MAX \u003d active_card_max\n\n        self.MATCHING_CUSTOMERS \u003d []\n        self.PERCENT_DIFFERENCE \u003d []\n        self.DAYS_DIFFERENCE \u003d []\n        self.DRAW_UP_DATE \u003d []\n\n        # remove punctuation\n        c_str \u003d name.translate(str.maketrans(\u0027\u0027, \u0027\u0027, string.punctuation))\n\n        f \u003d c_str.split()\n        self.WORD_LIST \u003d []\n        for w in f:\n            if w not in _common_words:\n                self.WORD_LIST.append(w)\n\n    def Match_Draw_Up_Customer(self, name, draw_up_date, active_card_max):\n\n        if (self.CUSTOMER \u003d\u003d name):\n            # exact match, already captured\n            return\n\n        c_str \u003d name.translate(str.maketrans(\u0027\u0027, \u0027\u0027, string.punctuation))\n\n        f \u003d c_str.split()\n\n        check_list \u003d []\n        for w in f:\n            if (w not in _common_words) and (len(w)\u003e1) and (not w.isnumeric()):\n                check_list.append(w)\n\n        percent_diff \u003d round((abs(self.ACTIVE_CARD_MAX - active_card_max) / ((self.ACTIVE_CARD_MAX+active_card_max)/2)),2)\n\n        #date_format \u003d \"%Y-%m-%d\"\n        #d1_date \u003d datetime.strptime(draw_up_date.astype(str), date_format)\n        #d2_date \u003d datetime.strptime(self.DRAW_DOWN_DATE.astype(str), date_format)\n\n        delta_between_drop_and_rise \u003d round(abs((draw_up_date-self.DRAW_DOWN_DATE).days)/30.,0)\n\n        for w_to_check in check_list:\n            for w in self.WORD_LIST:\n                if w_to_check\u003d\u003dw:\n\n                    if not name in(self.MATCHING_CUSTOMERS) and(delta_between_drop_and_rise\u003c\u003d4)and(percent_diff\u003c\u003d0.5) :\n                        self.MATCHING_CUSTOMERS.append(name)\n                        self.PERCENT_DIFFERENCE.append(percent_diff)\n                        self.DAYS_DIFFERENCE.append(delta_between_drop_and_rise)\n                        self.DRAW_UP_DATE.append(draw_up_date)\n                        break;"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "2173 screening against common words\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 19,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n\ndef do_save_log(_matching_process_log_time, _matching_process_log_event):\n\n    df_matching_log \u003d pd.DataFrame(_matching_process_log_time)\n    if len(df_matching_log)\u003e0:\n\n        df_matching_log.columns \u003d [\u0027LOG_TIME\u0027]\n        df_matching_log[\u0027LOG_EVENT\u0027] \u003d _matching_process_log_event\n\n        MATCHING_PROCESS_LOG_V_df \u003d df_matching_log\n        MATCHING_PROCESS_LOG_V \u003d dataiku.Dataset(\"MATCHING_PROCESS_LOG_V\")\n        MATCHING_PROCESS_LOG_V.write_with_schema(MATCHING_PROCESS_LOG_V_df)\n\n        print()\n\ndef do_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date):\n\n    df_matches \u003d pd.DataFrame(_direct_customer)\n    if len(df_matches)\u003e0:\n\n        print()\n        print(\"saving\", len(df_matches), \"1-1 matching records\")\n        print()\n\n        df_matches.columns \u003d [\u0027CUSTOMER\u0027]\n        df_matches[\"MATCH_CUSTOMER\"] \u003d _direct_match\n        df_matches[\"DRAW_UP_DATE\"] \u003d _direct_draw_up_date\n\n        MATCHES_1_TO_1_STAGING_V_df \u003d df_matches\n        MATCHES_1_TO_1_STAGING_V \u003d dataiku.Dataset(\"MATCHES_1_TO_1_STAGING_V\")\n        MATCHES_1_TO_1_STAGING_V.write_with_schema(MATCHES_1_TO_1_STAGING_V_df)\n\n        print()\n\ndef do_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates):\n\n    df_multiple_matches \u003d pd.DataFrame(_multiple_customer)\n\n    if len(df_multiple_matches)\u003e0:\n\n        print()\n        print(\"saving\", len(df_multiple_matches), \"1-n matching records\")\n        print()\n\n        df_multiple_matches.columns \u003d [\u0027CUSTOMER\u0027]\n        df_multiple_matches[\"MATCH_CUSTOMER\"] \u003d _multiple_matches\n        df_multiple_matches[\"DRAW_UP_DATE\"] \u003d _multiple_drop_dates\n\n        MATCHES_1_TO_N_STAGING_V_df \u003d df_multiple_matches\n        MATCHES_1_TO_N_STAGING_V \u003d dataiku.Dataset(\"MATCHES_1_TO_N_STAGING_V\")\n        MATCHES_1_TO_N_STAGING_V.write_with_schema(MATCHES_1_TO_N_STAGING_V_df)\n\n        print()"
      ],
      "outputs": []
    },
    {
      "execution_count": 20,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from datetime import timedelta\n\ndf_down \u003d df_down_full\ndf_up \u003d df_up_full\n\n_processed_customers \u003d []\nverbose \u003d False\n\n_matching_process_log_time \u003d []\n_matching_process_log_event \u003d []\n\n_direct_customer \u003d []\n_direct_match \u003d []\n_direct_draw_up_date \u003d []\n\n_multiple_customer \u003d []\n_multiple_matches \u003d []\n_multiple_drop_dates \u003d []\n\n_no_match_customer \u003d []\n\nsave_every_n \u003d 50\nto_save_counter \u003d 0\nprint_every_n \u003d 25\n\nprint(len(df_down), \"filtered down rows\")\nprint(len(df_up), \"filtered up rows\")\n\n_customers \u003d []\n\nt0 \u003d time.time()\n\nfor index, row in df_down.iterrows():\n\n    customer \u003d row[\u0027CUSTOMER\u0027]\n    draw_down_date \u003d row[\u0027DRAW_DOWN_DATE\u0027]\n    active_card_max \u003d row[\u0027ACTIVE_CARD_MAX\u0027]\n\n    c \u003d Draw_Down_Customer(customer, draw_down_date, active_card_max)\n\n    _customers.append(c)\n\nidx \u003d 0\n\n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\" processing range \" + str(len(_customers)) + \" Draw Down Customers\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)\n\n\n\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "34027 filtered down rows\n72496 filtered up rows\n1 rows successfully written (sv4tdOl7O9)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 25,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "idx\u003d0\nfor c in _customers:\n\n    idx+\u003d1\n\n    print(c.CUSTOMER)\n    \n    date_start \u003d pd.to_datetime(c.DRAW_DOWN_DATE) +timedelta(days\u003d-120)\n    date_end \u003d pd.to_datetime(c.DRAW_DOWN_DATE) +timedelta(days\u003d120)\n\n    card_delta \u003d c.ACTIVE_CARD_MAX * 0.5\n    card_start \u003d c.ACTIVE_CARD_MAX - card_delta\n    card_end \u003d c.ACTIVE_CARD_MAX + card_delta\n\n    df_up \u003d df_up_full[(df_up_full.ACTIVE_CARD_MAX\u003e\u003dcard_start)\u0026\n                   (df_up_full.ACTIVE_CARD_MAX\u003c\u003dcard_end)\u0026\n                    (df_up_full.DRAW_UP_DATE \u003e\u003d pd.to_datetime(date_start))\u0026\n                  (df_up_full.DRAW_UP_DATE \u003c\u003d pd.to_datetime(date_end))].copy()\n    \n    df_up[\u0027distance\u0027] \u003d df_up.apply(lambda x: Levenshtein.ratio(x[\u0027CUSTOMER\u0027],c.CUSTOMER),axis\u003d1)\n    \n    df_up \u003d df_up[df_up.distance\u003e0.8]\n    \n    print(\"length:\", len(df_up))\n    print()\n    \n    if (idx\u003e\u003d2):\n        break;\n        \ndf_up.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": " DANLEY ELEC CONTRACTING LLC\nlength: 12346\n\n HOLDINGS LLC DBA SECURITY INDUSTRIES\nlength: 5913\n\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "                            CUSTOMER DRAW_UP_DATE  ACTIVE_CARD_MAX  distance\n166801                  YOUR SERVICE   2019-06-01              9.0  0.360000\n220275                 034435 NB LTD   2019-10-01              6.0  0.240000\n220272                 057032 NB LTD   2019-11-01             15.0  0.240000\n220245                0869711 BC LTD   2019-11-01             11.0  0.196078\n220242  0897 CARDINAL HEALTH IPS 790   2019-10-01              9.0  0.338462",
            "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eCUSTOMER\u003c/th\u003e\n      \u003cth\u003eDRAW_UP_DATE\u003c/th\u003e\n      \u003cth\u003eACTIVE_CARD_MAX\u003c/th\u003e\n      \u003cth\u003edistance\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e166801\u003c/th\u003e\n      \u003ctd\u003eYOUR SERVICE\u003c/td\u003e\n      \u003ctd\u003e2019-06-01\u003c/td\u003e\n      \u003ctd\u003e9.0\u003c/td\u003e\n      \u003ctd\u003e0.360000\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e220275\u003c/th\u003e\n      \u003ctd\u003e034435 NB LTD\u003c/td\u003e\n      \u003ctd\u003e2019-10-01\u003c/td\u003e\n      \u003ctd\u003e6.0\u003c/td\u003e\n      \u003ctd\u003e0.240000\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e220272\u003c/th\u003e\n      \u003ctd\u003e057032 NB LTD\u003c/td\u003e\n      \u003ctd\u003e2019-11-01\u003c/td\u003e\n      \u003ctd\u003e15.0\u003c/td\u003e\n      \u003ctd\u003e0.240000\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e220245\u003c/th\u003e\n      \u003ctd\u003e0869711 BC LTD\u003c/td\u003e\n      \u003ctd\u003e2019-11-01\u003c/td\u003e\n      \u003ctd\u003e11.0\u003c/td\u003e\n      \u003ctd\u003e0.196078\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e220242\u003c/th\u003e\n      \u003ctd\u003e0897 CARDINAL HEALTH IPS 790\u003c/td\u003e\n      \u003ctd\u003e2019-10-01\u003c/td\u003e\n      \u003ctd\u003e9.0\u003c/td\u003e\n      \u003ctd\u003e0.338462\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    for index_up, row_up in df_up.iterrows():\n\n        customer \u003d row_up[\u0027CUSTOMER\u0027]\n        draw_up_date \u003d row_up[\u0027DRAW_UP_DATE\u0027]\n        active_card_max \u003d row_up[\u0027ACTIVE_CARD_MAX\u0027]\n\n        c.Match_Draw_Up_Customer(customer, draw_up_date, active_card_max)\n\n    if len(c.MATCHING_CUSTOMERS)\u003d\u003d1:\n\n        if not c.CUSTOMER in (_processed_customers):\n\n            to_save_counter +\u003d 1\n\n            _direct_customer.append(c.CUSTOMER)\n            _processed_customers.append(c.CUSTOMER)\n            _direct_match.append(c.MATCHING_CUSTOMERS[0])\n            _processed_customers.append(c.MATCHING_CUSTOMERS[0])\n            _direct_draw_up_date.append(c.DRAW_UP_DATE[0])\n\n            if verbose:\n                print()\n                print(\"DIRECT\")\n                print(c.CUSTOMER, c.WORD_LIST)\n                print(c.MATCHING_CUSTOMERS)\n                print(c.PERCENT_DIFFERENCE)\n                print(c.DAYS_DIFFERENCE)\n                print(\"\u003d\u003d\u003d\u003d\u003d\")\n                print()\n\n    elif len(c.MATCHING_CUSTOMERS)\u003e1:\n\n        if not c.CUSTOMER in (_processed_customers):\n\n            to_save_counter +\u003d 1\n\n            _multiple_customer.append(c.CUSTOMER)\n            _processed_customers.append(c.CUSTOMER)\n            _multiple_matches.append(c.MATCHING_CUSTOMERS)\n            _multiple_drop_dates.append(c.DRAW_UP_DATE)\n\n        if verbose:\n            print()\n            print(\"MULTIPLE\")\n            print(c.CUSTOMER, c.WORD_LIST)\n            print(c.MATCHING_CUSTOMERS)\n            print(c.PERCENT_DIFFERENCE)\n            print(c.DAYS_DIFFERENCE)\n            print(\"\u003d\u003d\u003d\u003d\u003d\")\n            print()\n\n    else:\n\n        # could not find a match, remove it from future processing\n        _no_match_customer.append(c.CUSTOMER)\n        _processed_customers.append(c.CUSTOMER)\n\n    if to_save_counter\u003e\u003dsave_every_n:\n\n        _matching_process_log_time.append(str(pd.Timestamp.now()))\n        _matching_process_log_event.append(\"writing datasets to snowflake\")\n        do_save_log(_matching_process_log_time, _matching_process_log_event)\n\n        do_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date)\n        do_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates)\n\n        _matching_process_log_time.append(str(pd.Timestamp.now()))\n        _matching_process_log_event.append(\"saved \" + str(to_save_counter) + \" records to snowflake.\")\n        do_save_log(_matching_process_log_time, _matching_process_log_event)\n\n        to_save_counter \u003d 0\n\n    t1 \u003d time.time()\n\n    avg_duration \u003d (((t1-t0)/idx)/60.0)\n\n    if idx % print_every_n \u003d\u003d 0:\n        idx_remaining \u003d len(_customers)-idx\n        print(\"processing\", idx, \"current record:\", c.CUSTOMER, \",\", idx_remaining, \"remaining\")\n        print(round(avg_duration,2), \"avg mins per iteration\",  round((avg_duration*idx_remaining)/60,2), \"estimated hrs remaining\")\n        print(len(_direct_customer), \"direct match records\", len(_multiple_customer), \"multiple match records\", len(_no_match_customer), \"no match records\")\n        print()\n\n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\"writing datasets to snowflake\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)\n\ndo_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date)\ndo_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates)\n\n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\"saved \" + str(to_save_counter) + \" records to snowflake.\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}