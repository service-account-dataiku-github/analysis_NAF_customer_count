{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-env_clc",
      "display_name": "Python (env env_clc)",
      "language": "python"
    },
    "associatedRecipe": "compute_MATCHES_1_TO_N_STAGING_V",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1667169923254
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1667169923254,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "Daniel.Vandermeer"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 14,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\n# Read recipe inputs\nCALCULATED_DRAW_DOWNS \u003d dataiku.Dataset(\"CALCULATED_DRAW_DOWNS\")\nCALCULATED_DRAW_DOWNS_df \u003d CALCULATED_DRAW_DOWNS.get_dataframe()\n\nCALCULATED_DRAW_UPS \u003d dataiku.Dataset(\"CALCULATED_DRAW_UPS\")\nCALCULATED_DRAW_UPS_df \u003d CALCULATED_DRAW_UPS.get_dataframe()\n\nCOMMON_WORDS \u003d dataiku.Dataset(\"NAFCUSTOMER_COMMON_WORDS_IN_NAMES\")\nCOMMON_WORDS_df \u003d COMMON_WORDS.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 15,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_down_full \u003d CALCULATED_DRAW_DOWNS_df\ndf_up_full \u003d CALCULATED_DRAW_UPS_df\ndf_common \u003d COMMON_WORDS_df\n\ndf_down_full.sort_values([\u0027CUSTOMER\u0027], inplace\u003dTrue)\ndf_up_full.sort_values([\u0027CUSTOMER\u0027], inplace\u003dTrue)\ndf_common.sort_values([\u0027WORD\u0027], inplace\u003dTrue)\n\nprint(len(df_down_full), \"draw downs full\")\nprint(len(df_up_full), \"draw ups full\")\nprint(len(df_common), \"common words\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "14444 draw downs full\n5848 draw ups full\n2173 common words\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 19,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import string\n\n_common_words \u003d df_common.WORD.unique()\nprint(len(_common_words), \"screening against common words\")\n\nclass Draw_Down_Customer:\n\n    def __init__(self, name, draw_down_date, active_card_max):\n\n        self.CUSTOMER \u003d name\n        self.DRAW_DOWN_DATE \u003d draw_down_date\n        self.ACTIVE_CARD_MAX \u003d active_card_max\n\n        self.MATCHING_CUSTOMERS \u003d []\n        self.PERCENT_DIFFERENCE \u003d []\n        self.DAYS_DIFFERENCE \u003d []\n        self.DRAW_UP_DATE \u003d []\n\n        # remove punctuation\n        c_str \u003d name.translate(str.maketrans(\u0027\u0027, \u0027\u0027, string.punctuation))\n\n        f \u003d c_str.split()\n        self.WORD_LIST \u003d []\n        for w in f:\n            if w not in _common_words:\n                self.WORD_LIST.append(w)\n\n    def Match_Draw_Up_Customer(self, name, draw_up_date, active_card_max):\n\n        if (self.CUSTOMER \u003d\u003d name):\n            # exact match, already captured\n            return\n\n        c_str \u003d name.translate(str.maketrans(\u0027\u0027, \u0027\u0027, string.punctuation))\n\n        f \u003d c_str.split()\n\n        check_list \u003d []\n        for w in f:\n            if (w not in _common_words) and (len(w)\u003e1) and (not w.isnumeric()):\n                check_list.append(w)\n\n        percent_diff \u003d round((abs(self.ACTIVE_CARD_MAX - active_card_max) / ((self.ACTIVE_CARD_MAX+active_card_max)/2)),2)\n\n        #date_format \u003d \"%Y-%m-%d\"\n        #d1_date \u003d datetime.strptime(draw_up_date.astype(str), date_format)\n        #d2_date \u003d datetime.strptime(self.DRAW_DOWN_DATE.astype(str), date_format)\n\n        delta_between_drop_and_rise \u003d round(abs((draw_up_date-self.DRAW_DOWN_DATE).days)/30.,0)\n\n        for w_to_check in check_list:\n            for w in self.WORD_LIST:\n                if w_to_check\u003d\u003dw:\n\n                    if not name in(self.MATCHING_CUSTOMERS) and(delta_between_drop_and_rise\u003c\u003d4)and(percent_diff\u003c\u003d0.5) :\n                        self.MATCHING_CUSTOMERS.append(name)\n                        self.PERCENT_DIFFERENCE.append(percent_diff)\n                        self.DAYS_DIFFERENCE.append(delta_between_drop_and_rise)\n                        self.DRAW_UP_DATE.append(draw_up_date)\n                        break;"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "2173 screening against common words\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n\ndef do_save_log(_matching_process_log_time, _matching_process_log_event):\n\n    df_matching_log \u003d pd.DataFrame(_matching_process_log_time)\n    if len(df_matching_log)\u003e0:\n\n        df_matching_log.columns \u003d [\u0027LOG_TIME\u0027]\n        df_matching_log[\u0027LOG_EVENT\u0027] \u003d _matching_process_log_event\n\n        MATCHING_PROCESS_LOG_V_df \u003d df_matching_log\n        MATCHING_PROCESS_LOG_V \u003d dataiku.Dataset(\"MATCHING_PROCESS_LOG_V\")\n        MATCHING_PROCESS_LOG_V.write_with_schema(MATCHING_PROCESS_LOG_V_df)\n\n        print()\n\ndef do_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date):\n\n    df_matches \u003d pd.DataFrame(_direct_customer)\n    if len(df_matches)\u003e0:\n\n        print()\n        print(\"saving\", len(df_matches), \"1-1 matching records\")\n        print()\n\n        df_matches.columns \u003d [\u0027CUSTOMER\u0027]\n        df_matches[\"MATCH_CUSTOMER\"] \u003d _direct_match\n        df_matches[\"DRAW_UP_DATE\"] \u003d _direct_draw_up_date\n\n        MATCHES_1_TO_1_STAGING_V_df \u003d df_matches\n        MATCHES_1_TO_1_STAGING_V \u003d dataiku.Dataset(\"MATCHES_1_TO_1_STAGING_V\")\n        MATCHES_1_TO_1_STAGING_V.write_with_schema(MATCHES_1_TO_1_STAGING_V_df)\n\n        print()\n\ndef do_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates):\n\n    df_multiple_matches \u003d pd.DataFrame(_multiple_customer)\n\n    if len(df_multiple_matches)\u003e0:\n\n        print()\n        print(\"saving\", len(df_multiple_matches), \"1-n matching records\")\n        print()\n\n        df_multiple_matches.columns \u003d [\u0027CUSTOMER\u0027]\n        df_multiple_matches[\"MATCH_CUSTOMER\"] \u003d _multiple_matches\n        df_multiple_matches[\"DRAW_UP_DATE\"] \u003d _multiple_drop_dates\n\n        MATCHES_1_TO_N_STAGING_V_df \u003d df_multiple_matches\n        MATCHES_1_TO_N_STAGING_V \u003d dataiku.Dataset(\"MATCHES_1_TO_N_STAGING_V\")\n        MATCHES_1_TO_N_STAGING_V.write_with_schema(MATCHES_1_TO_N_STAGING_V_df)\n\n        print()"
      ],
      "outputs": []
    },
    {
      "execution_count": 32,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_down \u003d df_down_full\ndf_down[\u0027DRAW_DOWN_DATE\u0027] \u003d df_down[\u0027DRAW_DOWN_DATE\u0027].dt.date\ndf_up \u003d df_up_full\n\n_processed_customers \u003d []\nverbose \u003d False\n\n_matching_process_log_time \u003d []\n_matching_process_log_event \u003d []\n\n_direct_customer \u003d []\n_direct_match \u003d []\n_direct_draw_up_date \u003d []\n\n_multiple_customer \u003d []\n_multiple_matches \u003d []\n_multiple_drop_dates \u003d []\n\n_no_match_customer \u003d []\n\nsave_every_n \u003d 50\nto_save_counter \u003d 0\nprint_every_n \u003d 25\n\nprint(len(df_down), \"filtered down rows\")\nprint(len(df_up), \"filtered up rows\")\n\n_customers \u003d []\n\nt0 \u003d time.time()\n\nfor index, row in df_down.iterrows():\n    \n    customer \u003d row[\u0027CUSTOMER\u0027]\n    draw_down_date \u003d row[\u0027DRAW_DOWN_DATE\u0027]\n    active_card_max \u003d row[\u0027ACTIVE_CARD_MAX\u0027]\n\n    c \u003d Draw_Down_Customer(customer, draw_down_date, active_card_max)\n\n    _customers.append(c)\n\nidx \u003d 0\n\n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\" processing range \" + str(len(_customers)) + \" Draw Down Customers\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)\n\nmax_idx \u003d 5\n\nfor c in _customers:\n    \n    idx+\u003d1\n    \n    #self.CUSTOMER \u003d name\n    #self.DRAW_DOWN_DATE \u003d draw_down_date\n    #self.ACTIVE_CARD_MAX \u003d active_card_max\n    print(c.CUSTOMER, c.DRAW_DOWN_DATE, c.ACTIVE_CARD_MAX)\n\n    if idx\u003emax_idx:\n        break;\n        \n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can only use .dt accessor with datetimelike values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-32-38795b261f5b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_down\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mdf_down_full\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mdf_down\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u0027DRAW_DOWN_DATE\u0027\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mdf_down\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u0027DRAW_DOWN_DATE\u0027\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_up\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mdf_up_full\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_processed_customers\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/data/dataiku/dss_data/code-envs/python/env_clc/lib64/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5268\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5269\u001b[0m         ):\n\u001b[0;32m-\u003e 5270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/data/dataiku/dss_data/code-envs/python/env_clc/lib64/python3.6/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# we\u0027re accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 187\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/data/dataiku/dss_data/code-envs/python/env_clc/lib64/python3.6/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeProperties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 338\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
          ]
        }
      ]
    },
    {
      "execution_count": 30,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_down.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "                                   CUSTOMER            DRAW_DOWN_DATE  ACTIVE_CARD_MAX\n0      HOLDINGS LLC DBA SECURITY INDUSTRIES 2019-08-01 00:00:00+00:00             10.0\n9999                    0067 BLACK \u0026 DECKER 2020-10-01 00:00:00+00:00            687.0\n9998                          0452009108911 2021-07-01 00:00:00+00:00              9.0\n9997      0496003403045 EAST BAY MECHANICAL 2020-03-01 00:00:00+00:00             18.0\n9996              0516 MONSANTO CANADA INC. 2020-10-01 00:00:00+00:00            123.0",
            "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eCUSTOMER\u003c/th\u003e\n      \u003cth\u003eDRAW_DOWN_DATE\u003c/th\u003e\n      \u003cth\u003eACTIVE_CARD_MAX\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003eHOLDINGS LLC DBA SECURITY INDUSTRIES\u003c/td\u003e\n      \u003ctd\u003e2019-08-01 00:00:00+00:00\u003c/td\u003e\n      \u003ctd\u003e10.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e9999\u003c/th\u003e\n      \u003ctd\u003e0067 BLACK \u0026amp; DECKER\u003c/td\u003e\n      \u003ctd\u003e2020-10-01 00:00:00+00:00\u003c/td\u003e\n      \u003ctd\u003e687.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e9998\u003c/th\u003e\n      \u003ctd\u003e0452009108911\u003c/td\u003e\n      \u003ctd\u003e2021-07-01 00:00:00+00:00\u003c/td\u003e\n      \u003ctd\u003e9.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e9997\u003c/th\u003e\n      \u003ctd\u003e0496003403045 EAST BAY MECHANICAL\u003c/td\u003e\n      \u003ctd\u003e2020-03-01 00:00:00+00:00\u003c/td\u003e\n      \u003ctd\u003e18.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e9996\u003c/th\u003e\n      \u003ctd\u003e0516 MONSANTO CANADA INC.\u003c/td\u003e\n      \u003ctd\u003e2020-10-01 00:00:00+00:00\u003c/td\u003e\n      \u003ctd\u003e123.0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 26,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "0        2019-08-01\n9999     2020-10-01\n9998     2021-07-01\n9997     2020-03-01\n9996     2020-10-01\n            ...    \n10005    2021-12-01\n10004    2021-04-01\n10003    2021-11-01\n10002    2022-01-01\n10001    2021-09-01\nName: DRAW_DOWN_DATE, Length: 14444, dtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\" processing range \" + str(len(_customers)) + \" Draw Down Customers\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)\n\nif verbose:\n    print(\" processing range from \" + str(len(_customers)) + \" Draw Down Customers\")\n\nfor c in _customers:\n\n    idx+\u003d1\n    \n    for index_up, row_up in df_up.iterrows():\n\n        customer \u003d row_up[\u0027CUSTOMER\u0027]\n        draw_up_date \u003d row_up[\u0027DRAW_UP_DATE\u0027]\n        mean_du \u003d row_up[\u0027MEAN_DU\u0027]\n        std_du \u003d row_up[\u0027STD_DU\u0027]\n        active_card_max \u003d row_up[\u0027ACTIVE_CARD_MAX\u0027]\n\n        c.Match_Draw_Up_Customer(customer, draw_up_date, mean_du, std_du, active_card_max)\n\n    if len(c.MATCHING_CUSTOMERS)\u003d\u003d1:\n\n        if not c.CUSTOMER in (_processed_customers):\n\n            to_save_counter +\u003d 1\n\n            _direct_customer.append(c.CUSTOMER)\n            _processed_customers.append(c.CUSTOMER)\n            _direct_match.append(c.MATCHING_CUSTOMERS[0])\n            _processed_customers.append(c.MATCHING_CUSTOMERS[0])\n            _direct_draw_up_date.append(c.DRAW_UP_DATE[0])\n\n            if verbose:\n                print()\n                print(\"DIRECT\")\n                print(c.CUSTOMER, c.WORD_LIST)\n                print(c.MATCHING_CUSTOMERS)\n                print(c.PERCENT_DIFFERENCE)\n                print(c.DAYS_DIFFERENCE)\n                print(\"\u003d\u003d\u003d\u003d\u003d\")\n                print()\n\n    elif len(c.MATCHING_CUSTOMERS)\u003e1:\n\n        if not c.CUSTOMER in (_processed_customers):\n\n            to_save_counter +\u003d 1\n\n            _multiple_customer.append(c.CUSTOMER)\n            _processed_customers.append(c.CUSTOMER)\n            _multiple_matches.append(c.MATCHING_CUSTOMERS)\n            _multiple_drop_dates.append(c.DRAW_UP_DATE)\n\n        if verbose:\n            print()\n            print(\"MULTIPLE\")\n            print(c.CUSTOMER, c.WORD_LIST)\n            print(c.MATCHING_CUSTOMERS)\n            print(c.PERCENT_DIFFERENCE)\n            print(c.DAYS_DIFFERENCE)\n            print(\"\u003d\u003d\u003d\u003d\u003d\")\n            print()\n\n    else:\n\n        # could not find a match, remove it from future processing\n        _no_match_customer.append(c.CUSTOMER)\n        _processed_customers.append(c.CUSTOMER)\n\n    if to_save_counter\u003e\u003dsave_every_n:\n\n        _matching_process_log_time.append(str(pd.Timestamp.now()))\n        _matching_process_log_event.append(\"writing datasets to snowflake\")\n        do_save_log(_matching_process_log_time, _matching_process_log_event)\n\n        do_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date)\n        do_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates)\n\n        _matching_process_log_time.append(str(pd.Timestamp.now()))\n        _matching_process_log_event.append(\"saved \" + str(to_save_counter) + \" records to snowflake.\")\n        do_save_log(_matching_process_log_time, _matching_process_log_event)\n\n        to_save_counter \u003d 0\n        \n    t1 \u003d time.time()\n    \n    avg_duration \u003d (((t1-t0)/idx)/60.0)\n    \n    if idx % print_every_n \u003d\u003d 0:\n        idx_remaining \u003d len(_customers)-idx\n        print(\"processing\", idx, \"current record:\", c.CUSTOMER, \",\", idx_remaining, \"remaining\")\n        print(round(avg_duration,2), \"avg mins per iteration\",  round((avg_duration*idx_remaining)/60,2), \"estimated hrs remaining\")\n        print(len(_direct_customer), \"direct match records\", len(_multiple_customer), \"multiple match records\", len(_no_match_customer), \"no match records\")\n        print()\n        \n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\"writing datasets to snowflake\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)\n\ndo_save_direct_matches(_direct_customer, _direct_match, _direct_draw_up_date)\ndo_save_multiple_matches(_multiple_customer, _multiple_matches, _multiple_drop_dates)\n\n_matching_process_log_time.append(str(pd.Timestamp.now()))\n_matching_process_log_event.append(\"saved \" + str(to_save_counter) + \" records to snowflake.\")\ndo_save_log(_matching_process_log_time, _matching_process_log_event)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute recipe outputs\n# TODO: Write here your actual code that computes the outputs\n# NB: DSS supports several kinds of APIs for reading and writing data. Please see doc.\n\n#MATCHES_1_TO_N_STAGING_V_df \u003d ... # Compute a Pandas dataframe to write into MATCHES_1_TO_N_STAGING_V\n#MATCHES_1_TO_1_STAGING_V_df \u003d ... # Compute a Pandas dataframe to write into MATCHES_1_TO_1_STAGING_V\n\n\n# Write recipe outputs\n#MATCHES_1_TO_N_STAGING_V \u003d dataiku.Dataset(\"MATCHES_1_TO_N_STAGING_V\")\n#MATCHES_1_TO_N_STAGING_V.write_with_schema(MATCHES_1_TO_N_STAGING_V_df)\n#MATCHES_1_TO_1_STAGING_V \u003d dataiku.Dataset(\"MATCHES_1_TO_1_STAGING_V\")\n#MATCHES_1_TO_1_STAGING_V.write_with_schema(MATCHES_1_TO_1_STAGING_V_df)"
      ],
      "outputs": []
    }
  ]
}