{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-env_clc-cpu-m-cpu-3-mem-4gb",
      "display_name": "Python in cpu-m-cpu-3-mem-4Gb (env env_clc)",
      "language": "python"
    },
    "associatedRecipe": "compute_CALCULATED_CARD_DRAW_DOWNS_FULL",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1665863285048
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1665863285048,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "Daniel.Vandermeer"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\nimport pickle\nfrom dateutil.relativedelta import relativedelta\nimport gc\nfrom re import finditer\n\n## Find DD DU\nfrom helper import preprocess_data\nfrom patterns import find_drawdowns, find_drawups\n\n## MATCHING\nimport name_matching\nfrom name_matching import name_match\nimport transaction_matching\nfrom transaction_matching import transaction_match\n\n## CONSOLIDATION\nfrom consolidation import combine_matches, consolidate_matches, find_attritions, find_new_accounts, get_attrition_status, get_new_account_status"
      ],
      "outputs": []
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "start_date \u003d dataiku.get_custom_variables()[\u0027start_date\u0027]\nend_date \u003d dataiku.get_custom_variables()[\u0027end_date\u0027]\n\nconsistency \u003d int(dataiku.get_custom_variables()[\u0027consistency\u0027])\ndrawdown_period_average \u003d int(dataiku.get_custom_variables()[\u0027drawdown_period_average\u0027])\ndrawdown \u003d int(dataiku.get_custom_variables()[\u0027drawdown\u0027])\ndrawdown_fwd_check \u003d int(dataiku.get_custom_variables()[\u0027drawdown_fwd_check\u0027])\ndrawdown_lookback_period \u003d int(dataiku.get_custom_variables()[\u0027drawdown_lookback_period\u0027])\ndrawup_lookfwd_period \u003d int(dataiku.get_custom_variables()[\u0027drawup_lookfwd_period\u0027])\nstatistics_period \u003d int(dataiku.get_custom_variables()[\u0027statistics_period\u0027])\ninactive_period \u003d int(dataiku.get_custom_variables()[\u0027inactive_period\u0027])\n\n## MATCHING VARIABLES\nmonth_diff_h \u003d int(dataiku.get_custom_variables()[\u0027month_diff_h\u0027])\nmonth_diff_l \u003d int(dataiku.get_custom_variables()[\u0027month_diff_l\u0027])\nsd_mul \u003d int(dataiku.get_custom_variables()[\u0027sd_mul\u0027])\nmax_city_distance \u003d int(dataiku.get_custom_variables()[\u0027max_city_distance\u0027])\nthreshold_score_step1 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step1\u0027])\nthreshold_score_step2 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step2\u0027])\n\n## RUN TYPE\nrun \u003d dataiku.get_custom_variables()[\u0027run_type\u0027]"
      ],
      "outputs": []
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def date_tz_naive(pd_s):\n    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))\n\n# Read recipe inputs\nNAFCUSTOMER_ACTIVE_CARDS_FULL \u003d dataiku.Dataset(\"NAFCUSTOMER_ACTIVE_CARDS_FULL\")\nNAFCUSTOMER_ACTIVE_CARDS_FULL_df \u003d NAFCUSTOMER_ACTIVE_CARDS_FULL.get_dataframe()\n\nprint(len(NAFCUSTOMER_ACTIVE_CARDS_FULL_df))\nNAFCUSTOMER_ACTIVE_CARDS_FULL_df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "16505348\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "                            CUSTOMER  REVENUE_YEAR  REVENUE_MONTH  ACTIVE_CARD_COUNT\n0                 HYUNTEC INDUSTRIES          2019              1                1.0\n1              TCK SERVICE GROUP INC          2019              1               12.0\n2           RAPTOR MINING PRODUCTS L          2019              1                3.0\n3                MARUE AND GERTZ LTD          2019              1                1.0\n4  CALIBER CONSTRUCTION SERVICES INC          2019              1                2.0",
            "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eCUSTOMER\u003c/th\u003e\n      \u003cth\u003eREVENUE_YEAR\u003c/th\u003e\n      \u003cth\u003eREVENUE_MONTH\u003c/th\u003e\n      \u003cth\u003eACTIVE_CARD_COUNT\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003eHYUNTEC INDUSTRIES\u003c/td\u003e\n      \u003ctd\u003e2019\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003eTCK SERVICE GROUP INC\u003c/td\u003e\n      \u003ctd\u003e2019\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e12.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003eRAPTOR MINING PRODUCTS L\u003c/td\u003e\n      \u003ctd\u003e2019\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e3.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003eMARUE AND GERTZ LTD\u003c/td\u003e\n      \u003ctd\u003e2019\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003eCALIBER CONSTRUCTION SERVICES INC\u003c/td\u003e\n      \u003ctd\u003e2019\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e2.0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v[df_v.CUSTOMER.str.startswith(\u0027RARITAN\u0027)].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "                                              CUSTOMER REVENUE_DATE  ACTIVE_CARD_COUNT\n57234                       RARITAN GROUP INCORPORATED   2019-01-01               11.0\n71751                          RARITAN BAY MEDICAL CTR   2019-01-01                3.0\n133271                                     RARITAN INC   2019-01-01                1.0\n159386  RARITAN TOWNSHIP MUNICIPAL UTILITIES AUTHORITY   2019-01-01                2.0\n252336                      RARITAN BAY MEDICAL CENTER   2019-01-01                5.0",
            "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eCUSTOMER\u003c/th\u003e\n      \u003cth\u003eREVENUE_DATE\u003c/th\u003e\n      \u003cth\u003eACTIVE_CARD_COUNT\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e57234\u003c/th\u003e\n      \u003ctd\u003eRARITAN GROUP INCORPORATED\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e11.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e71751\u003c/th\u003e\n      \u003ctd\u003eRARITAN BAY MEDICAL CTR\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e3.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e133271\u003c/th\u003e\n      \u003ctd\u003eRARITAN INC\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e1.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e159386\u003c/th\u003e\n      \u003ctd\u003eRARITAN TOWNSHIP MUNICIPAL UTILITIES AUTHORITY\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e2.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e252336\u003c/th\u003e\n      \u003ctd\u003eRARITAN BAY MEDICAL CENTER\u003c/td\u003e\n      \u003ctd\u003e2019-01-01\u003c/td\u003e\n      \u003ctd\u003e5.0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v \u003d NAFCUSTOMER_ACTIVE_CARDS_FULL_df\n\nprint(len(df_v))\ndf_v[\u0027REVENUE_DATE\u0027] \u003d df_v.REVENUE_MONTH.astype(str) + \"/01/\" + df_v.REVENUE_YEAR.astype(str)\ndf_v[\u0027REVENUE_DATE\u0027] \u003d date_tz_naive(df_v[\u0027REVENUE_DATE\u0027])\nprint(len(df_v))\n\ndf_v \u003d df_v[[\u0027CUSTOMER\u0027,\u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]]\n\ndf_v_max \u003d df_v[[\u0027CUSTOMER\u0027,\u0027ACTIVE_CARD_COUNT\u0027]]\ndf_max \u003d df_v_max.groupby(by\u003d[\"CUSTOMER\"]).max().reset_index()\ndf_max.columns \u003d [\u0027CUSTOMER\u0027, \u0027ACTIVE_CARD_MAX\u0027]\n\nprint(len(df_v))\ndf_v.dropna(subset\u003d[\u0027CUSTOMER\u0027], inplace\u003dTrue)\nprint(len(df_v))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "16505348\n16505348\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(len(df_v))\ndf_v \u003d df_v[df_v[\u0027REVENUE_DATE\u0027].between(pd.to_datetime(start_date), pd.to_datetime(end_date))].copy()\ndf_v \u003d df_v.dropna(subset\u003d[\u0027CUSTOMER\u0027])\nprint(len(df_v))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v[\u0027REVENUE_DATE\u0027] \u003d pd.to_datetime(df_v[\u0027REVENUE_DATE\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v.sort_values([\u0027REVENUE_DATE\u0027], inplace\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "seen_accounts \u003d df_v[df_v[\u0027ACTIVE_CARD_COUNT\u0027] \u003e 0].groupby([\u0027CUSTOMER\u0027], as_index\u003dFalse)[[\u0027REVENUE_DATE\u0027]].first()\nseen_accounts[\u0027FIRST_DATE\u0027] \u003d seen_accounts[\u0027REVENUE_DATE\u0027] - pd.DateOffset(months\u003d1)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v.REVENUE_DATE.value_counts(dropna\u003dFalse)\nprint(len(df_v))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom dateutil.relativedelta import relativedelta\nfrom helper import *"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df \u003d df_v\nperiod_end_date \u003d end_date\nmatch_type \u003d \u0027program_flip\u0027\nperiod_start_date\u003dNone\nsplit\u003dNone"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "drawdown \u003d (100 - drawdown)/100\ndrawdown_fwd_check /\u003d 100\n\ninactive_date_start \u003d pd.to_datetime(period_end_date) + relativedelta(months\u003d-inactive_period)\n\ndf \u003d df[df[\u0027REVENUE_DATE\u0027] \u003c\u003d period_end_date].copy()\n\nif period_start_date:\n    period_start_date \u003d pd.to_datetime(period_start_date)\n    df \u003d df[df[\u0027REVENUE_DATE\u0027] \u003e\u003d period_start_date].copy()\n\nall_account_ids \u003d list(df[\u0027CUSTOMER\u0027].unique())\n\nif not split:\n    split\u003d1\n\nall_account_ids_n \u003d list(split_list(all_account_ids, split))\n\ndrop_df \u003d pd.DataFrame()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_consistent_cust(df, consecutive\u003d3):\n    \u0027\u0027\u0027returns a list of customers who are consistent for 3 (default value) months\u0027\u0027\u0027\n\n    ## Needs only these columns [\u0027customer_account_name\u0027, \u0027revenue_month\u0027, \u0027purchase_gallons_qty\u0027]\n\n    df \u003d df[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]].copy()\n    df.sort_values(by\u003d[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n\n    z \u003d (df.groupby([\u0027CUSTOMER\u0027])[\u0027REVENUE_DATE\u0027].diff(1)/np.timedelta64(1, \u0027M\u0027))\n    z \u003d z.round(0)\n    z \u003d (z \u003d\u003d 1).astype(\u0027int\u0027)\n    df[\u0027CUST_CONS\u0027] \u003d (z * (z.groupby((z !\u003d z.shift()).cumsum()).cumcount() + 2))\n    cust_cons \u003d df.groupby(\u0027CUSTOMER\u0027)[\u0027CUST_CONS\u0027].max()\n\n    return list(cust_cons[cust_cons\u003e\u003dconsecutive].index)\n\ndef add_padding_func(df, padding\u003d12, last_date\u003dNone):\n    \u0027\u0027\u0027\n    Fills all the zeros in between for intermittent data and also fills the trailing data with\n    12 zeros or till the last date whichever is earlier\n    \u0027\u0027\u0027\n\n    cols \u003d [\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027]\n\n    common_cols \u003d set(df.columns).intersection(set(cols))\n\n    profile \u003d df[common_cols].drop_duplicates()\n\n    vol \u003d df[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027ACTIVE_CARD_COUNT\u0027]].copy()\n    vol \u003d vol.groupby([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])[[\u0027ACTIVE_CARD_COUNT\u0027]].sum().reset_index()\n    vol.reset_index(drop\u003dTrue, inplace\u003dTrue)\n\n    vol.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n    vol.reset_index(drop\u003dTrue, inplace\u003dTrue)\n\n    last_rev_date \u003d vol.groupby([\u0027CUSTOMER\u0027])[[\u0027REVENUE_DATE\u0027]].last()\n    last_rev_date \u003d last_rev_date[last_rev_date[\u0027REVENUE_DATE\u0027] \u003c pd.to_datetime(last_date)]\n    last_rev_date[\u0027REVENUE_DATE\u0027] \u003d last_rev_date[\u0027REVENUE_DATE\u0027] + pd.DateOffset(months\u003dpadding)\n    last_rev_date[\u0027LAST_DATE\u0027] \u003d pd.to_datetime(last_date)\n    last_rev_date[\u0027REVENUE_DATE\u0027] \u003d last_rev_date[[\u0027REVENUE_DATE\u0027,\u0027LAST_DATE\u0027]].min(axis\u003d1)\n    last_rev_date.drop([\u0027LAST_DATE\u0027], axis\u003d1, inplace\u003dTrue)\n    last_rev_date.reset_index(inplace\u003dTrue)\n    vol \u003d pd.concat([vol, last_rev_date], ignore_index\u003dTrue)\n    vol.fillna(0, inplace\u003dTrue)\n    vol \u003d (vol.set_index(\u0027REVENUE_DATE\u0027).groupby(\u0027CUSTOMER\u0027).resample(\u0027MS\u0027).asfreq()\n                  .drop([\u0027CUSTOMER\u0027], 1).reset_index())\n    vol.fillna(0, inplace\u003dTrue)\n    df \u003d vol.merge(profile, how\u003d\u0027left\u0027, on \u003d [\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])\n    df.fillna(method\u003d\u0027ffill\u0027, inplace\u003dTrue)\n\n    return df\n\ndef find_average_func(dd_find, n\u003d12):\n\n    dd_find.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n    dd_find2 \u003d dd_find.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], ascending\u003d[True, False]).reset_index(drop\u003dTrue)\n\n    dd_find.reset_index(drop\u003dTrue, inplace\u003dTrue)\n    dd_find[\u0027LAST_N_MONTHS_AVG\u0027] \u003d dd_find.groupby([\u0027CUSTOMER\u0027])[\u0027ACTIVE_CARD_COUNT\u0027]\\\n                                        .rolling(n, min_periods\u003d1).mean().reset_index(drop\u003dTrue)\n    dd_find2[\u0027NEXT_N_MONTHS_AVG\u0027] \u003d dd_find2.groupby([\u0027CUSTOMER\u0027])[\u0027ACTIVE_CARD_COUNT\u0027]\\\n                                        .rolling(n, min_periods\u003d1).mean().reset_index(drop\u003dTrue)\n\n    dd_find[\u0027LAST_N_MONTHS_AVG\u0027] \u003d dd_find.groupby(\u0027CUSTOMER\u0027)[\u0027LAST_N_MONTHS_AVG\u0027].shift(1)\n    dd_find2[\u0027NEXT_N_MONTHS_AVG\u0027] \u003d dd_find2.groupby(\u0027CUSTOMER\u0027)[\u0027NEXT_N_MONTHS_AVG\u0027].shift(1)\n\n    dd_find \u003d dd_find.merge(dd_find2[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027, \u0027NEXT_N_MONTHS_AVG\u0027]],\n                on\u003d[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027])\n\n    return dd_find"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for sublist in tqdm(all_account_ids_n):\n\n    dd_find \u003d df[df[\u0027CUSTOMER\u0027].isin(sublist)].copy()\n\n    consistent_customers_dd \u003d find_consistent_cust(dd_find, consecutive\u003dconsistency)\n    if len(consistent_customers_dd) \u003d\u003d 0:\n        continue\n\n    dd_find \u003d dd_find[dd_find[\u0027CUSTOMER\u0027].isin(consistent_customers_dd)].copy()\n    dd_find \u003d add_padding_func(dd_find, padding\u003dstatistics_period, last_date\u003dperiod_end_date)\n    dd_find \u003d find_average_func(dd_find, n\u003dstatistics_period)\n\n    dd_find[\u0027DD_INDICATOR\u0027] \u003d np.where(((drawdown*(dd_find[\u0027LAST_N_MONTHS_AVG\u0027].round(3)) \u003e\n                                     dd_find[\u0027ACTIVE_CARD_COUNT\u0027].round(3)) \u0026\n                                    (dd_find[\u0027NEXT_N_MONTHS_AVG\u0027].round(3) \u003c\n                                     drawdown_fwd_check*dd_find[\u0027LAST_N_MONTHS_AVG\u0027].round(3))),\n                                   True, False)\n\n    ## Find the first drawdown and also the list of customers\n    pflip_dd \u003d dd_find[dd_find[\u0027DD_INDICATOR\u0027] \u003d\u003d True].copy()\n    pflip_dd.drop_duplicates(\u0027CUSTOMER\u0027, inplace\u003dTrue)\n    first_drop_idx \u003d pflip_dd.index\n    pflip_dd_customers \u003d list(dd_find[\u0027CUSTOMER\u0027].unique())\n    first_drop \u003d dd_find.iloc[first_drop_idx]\n\n    ## Identify the lookback period\n    first_drop \u003d first_drop[[\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027]].copy()\n    first_drop \u003d first_drop[first_drop[\u0027REVENUE_DATE\u0027] \u003c\u003d inactive_date_start].copy()\n    first_drop[\u0027START_DATE\u0027]  \u003d first_drop[\u0027REVENUE_DATE\u0027] - pd.DateOffset(months\u003ddrawdown_lookback_period)\n    first_drop.rename(columns \u003d {\u0027REVENUE_DATE\u0027:\u0027DD_DATE\u0027}, inplace\u003dTrue)\n    dd_find_df \u003d dd_find[dd_find[\u0027CUSTOMER\u0027].isin(pflip_dd_customers)]\n    dd_find_df \u003d dd_find_df.merge(first_drop, on\u003d[\u0027CUSTOMER\u0027])\n    dd_find_df \u003d dd_find_df[dd_find_df[\u0027REVENUE_DATE\u0027].between(dd_find_df[\u0027START_DATE\u0027],dd_find_df[\u0027DD_DATE\u0027])].copy()\n\n    ## Compute the sharpest fall from the lookback period\n    dd_find_df.sort_values([\u0027CUSTOMER\u0027, \u0027REVENUE_DATE\u0027], inplace\u003dTrue)\n    dd_find_df[\u0027DROP\u0027] \u003d dd_find_df.groupby([\u0027CUSTOMER\u0027])[\u0027ACTIVE_CARD_COUNT\u0027].diff(-1)\n\n    ## Find the corresponding period and remove duplicates in case of a similar values\n    drop_idx \u003d dd_find_df.groupby([\u0027CUSTOMER\u0027])[\u0027DROP\u0027].transform(max) \u003d\u003d dd_find_df[\u0027DROP\u0027]\n    drop_month_df \u003d dd_find_df[drop_idx].copy()\n    drop_month_df.drop_duplicates([\u0027CUSTOMER\u0027], inplace\u003dTrue)\n\n    ## remove the first record\n    dd_find \u003d dd_find.groupby(\u0027CUSTOMER\u0027).apply(lambda group: group.iloc[1:, 1:]).reset_index()\n    dd_find.drop(\u0027level_1\u0027, axis\u003d1, inplace\u003dTrue)\n\n    ## Find the time periods for calculating statistics (mean and standard deviation)\n    drop_month_df.rename(columns \u003d {\u0027REVENUE_DATE\u0027:\u0027DROP_DATE\u0027}, inplace\u003dTrue)\n    dd_find \u003d dd_find.merge(drop_month_df[[\u0027CUSTOMER\u0027, \u0027DROP_DATE\u0027]], on\u003d\u0027CUSTOMER\u0027)\n    dd_find[\u0027END_DATE\u0027] \u003d dd_find[\u0027DROP_DATE\u0027] - pd.DateOffset(months\u003d3)\n    dd_find[\u0027START_DATE\u0027] \u003d dd_find[\u0027END_DATE\u0027] - pd.DateOffset(months\u003dstatistics_period-1)\n    pflip_12_data \u003d dd_find[dd_find[\u0027REVENUE_DATE\u0027].between(dd_find[\u0027START_DATE\u0027], dd_find[\u0027END_DATE\u0027])].copy()\n\n    ## Calculate Mean and Standard Deviation\n    dd_stat \u003d pflip_12_data.groupby([\u0027CUSTOMER\u0027], as_index\u003dFalse).agg({\u0027ACTIVE_CARD_COUNT\u0027:[\u0027mean\u0027,\u0027std\u0027]})\n    dd_stat.columns \u003d [\u0027CUSTOMER_DD\u0027, \u0027MEAN_DD\u0027,\u0027STD_DD\u0027]\n    drop_month_df \u003d drop_month_df.merge(dd_stat,\n                                        left_on\u003d\u0027CUSTOMER\u0027,\n                                        right_on\u003d\u0027CUSTOMER_DD\u0027,\n                                        how\u003d\u0027left\u0027)\n\n    drop_df \u003d pd.concat([drop_df, drop_month_df], ignore_index\u003dTrue)\n\ndrop_df.drop([\u0027CUSTOMER_DD\u0027], axis\u003d1, inplace\u003dTrue)\ndrop_df.rename(columns\u003d{\u0027DROP_DATE\u0027:\u0027DRAW_DOWN_DATE\u0027,\n                        \u0027DROP\u0027:\u0027DROP_QTY\u0027}, inplace\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(drop_df.CUSTOMER.unique())"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "drop_df\ndrop_df \u003d drop_df[[\u0027CUSTOMER\u0027,\u0027DRAW_DOWN_DATE\u0027,\u0027MEAN_DD\u0027,\u0027STD_DD\u0027]]\ndrop_df.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(len(drop_df))\ndrop_df \u003d pd.merge(drop_df, df_max, how\u003d\u0027left\u0027, on\u003d\u0027CUSTOMER\u0027)\nprint(len(drop_df))\ndrop_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(len(drop_df))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\nCALCULATED_CARD_DRAW_DOWNS_FULL_df \u003d drop_df\n\n\n# Write recipe outputs\nCALCULATED_CARD_DRAW_DOWNS_FULL \u003d dataiku.Dataset(\"CALCULATED_CARD_DRAW_DOWNS_FULL\")\nCALCULATED_CARD_DRAW_DOWNS_FULL.write_with_schema(CALCULATED_CARD_DRAW_DOWNS_FULL_df)"
      ],
      "outputs": []
    }
  ]
}