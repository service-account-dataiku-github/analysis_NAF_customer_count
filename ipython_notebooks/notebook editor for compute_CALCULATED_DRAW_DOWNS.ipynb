{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python in cpu-m-cpu-3-mem-4Gb (builtin env)",
      "language": "python",
      "name": "py-dku-containerized-venv--cpu-m-cpu-3-mem-4gb"
    },
    "associatedRecipe": "compute_CALCULATED_DRAW_DOWNS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1665593021198
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1665593021198,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "import pandas as pd, numpy as np\n",
        "from dataiku import pandasutils as pdu\n",
        "\n",
        "import pickle\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import gc\n",
        "from re import finditer\n",
        "\n",
        "## Find DD DU\n",
        "from helper import preprocess_data\n",
        "from patterns import find_drawdowns, find_drawups\n",
        "\n",
        "## MATCHING\n",
        "import name_matching\n",
        "from name_matching import name_match\n",
        "import transaction_matching\n",
        "from transaction_matching import transaction_match\n",
        "\n",
        "## CONSOLIDATION\n",
        "from consolidation import combine_matches, consolidate_matches, find_attritions, find_new_accounts, get_attrition_status, get_new_account_status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "start_date \u003d dataiku.get_custom_variables()[\u0027start_date\u0027]\n",
        "end_date \u003d dataiku.get_custom_variables()[\u0027end_date\u0027]\n",
        "\n",
        "consistency \u003d int(dataiku.get_custom_variables()[\u0027consistency\u0027])\n",
        "drawdown_period_average \u003d int(dataiku.get_custom_variables()[\u0027drawdown_period_average\u0027])\n",
        "drawdown \u003d int(dataiku.get_custom_variables()[\u0027drawdown\u0027])\n",
        "drawdown_fwd_check \u003d int(dataiku.get_custom_variables()[\u0027drawdown_fwd_check\u0027])\n",
        "drawdown_lookback_period \u003d int(dataiku.get_custom_variables()[\u0027drawdown_lookback_period\u0027])\n",
        "drawup_lookfwd_period \u003d int(dataiku.get_custom_variables()[\u0027drawup_lookfwd_period\u0027])\n",
        "statistics_period \u003d int(dataiku.get_custom_variables()[\u0027statistics_period\u0027])\n",
        "inactive_period \u003d int(dataiku.get_custom_variables()[\u0027inactive_period\u0027])\n",
        "\n",
        "## MATCHING VARIABLES\n",
        "month_diff_h \u003d int(dataiku.get_custom_variables()[\u0027month_diff_h\u0027])\n",
        "month_diff_l \u003d int(dataiku.get_custom_variables()[\u0027month_diff_l\u0027])\n",
        "sd_mul \u003d int(dataiku.get_custom_variables()[\u0027sd_mul\u0027])\n",
        "max_city_distance \u003d int(dataiku.get_custom_variables()[\u0027max_city_distance\u0027])\n",
        "threshold_score_step1 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step1\u0027])\n",
        "threshold_score_step2 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step2\u0027])\n",
        "\n",
        "## RUN TYPE\n",
        "run \u003d dataiku.get_custom_variables()[\u0027run_type\u0027]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "def date_tz_naive(pd_s):\n",
        "    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Read recipe inputs\n",
        "NAFCUSTOMER_C360_ACCOUNTS \u003d dataiku.Dataset(\"NAFCUSTOMER_C360_ACCOUNTS\")\n",
        "NAFCUSTOMER_C360_ACCOUNTS_df \u003d NAFCUSTOMER_C360_ACCOUNTS.get_dataframe()\n",
        "print(len(NAFCUSTOMER_C360_ACCOUNTS_df))\n",
        "\n",
        "NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED \u003d dataiku.Dataset(\"NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED\")\n",
        "NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED.get_dataframe()\n",
        "print(len(NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df\n",
        "\n",
        "print(len(df_v))\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d df_v.REVENUE_MONTH.astype(str) + \"/01/\" + df_v.REVENUE_YEAR.astype(str)\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d date_tz_naive(df_v[\u0027REVENUE_DATE\u0027])\n",
        "print(len(df_v))\n",
        "df_v.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "print(len(df_v))\n",
        "df_v \u003d df_v[df_v[\u0027REVENUE_DATE\u0027].between(pd.to_datetime(start_date), pd.to_datetime(end_date))].copy()\n",
        "df_v \u003d df_v.dropna(subset\u003d[\u0027CUSTOMER_ACCOUNT_ID\u0027])\n",
        "df_v \u003d df_v[df_v[\u0027CUSTOMER_SOURCE_SYSTEM_CODE\u0027].isin([\u0027TANDEM\u0027, \u0027SIEBEL\u0027])]\n",
        "print(len(df_v))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027] \u003d df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027].astype(\u0027int64\u0027)\n",
        "df_v[\u0027REVENUE_DATE\u0027] \u003d pd.to_datetime(df_v[\u0027REVENUE_DATE\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "states \u003d list(df_v[\u0027ACCOUNT_STATE\u0027].unique())\n",
        "states_dict \u003d {s:s.upper() for s in states}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v[\u0027ACCOUNT_STATE\u0027] \u003d df_v[\u0027ACCOUNT_STATE\u0027].map(states_dict)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "## remove the unneccesary columns\n",
        "remove_cols\u003d[\u0027REVENUE_MONTH\u0027,\u0027REVENUE_YEAR\u0027, \u0027REVENUE_QUARTER\u0027]\n",
        "df_v \u003d df_v.drop([x for x in remove_cols if x in df_v.columns], axis\u003d1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v.sort_values([\u0027REVENUE_DATE\u0027], inplace\u003dTrue)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "seen_accounts \u003d df_v[df_v[\u0027PURCHASE_GALLONS_QTY\u0027] \u003e 0].groupby([\u0027CUSTOMER_ACCOUNT_ID\u0027], as_index\u003dFalse)[[\u0027REVENUE_DATE\u0027]].first()\n",
        "seen_accounts[\u0027FIRST_DATE\u0027] \u003d seen_accounts[\u0027REVENUE_DATE\u0027] - pd.DateOffset(months\u003d1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df_v.REVENUE_DATE.value_counts(dropna\u003dFalse)\n",
        "print(len(df_v))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from helper import *\n",
        "\n",
        "#---------------------\n",
        "# input vars\n",
        "df \u003d df_v\n",
        "period_end_date \u003d end_date\n",
        "match_type \u003d \u0027program_flip\u0027\n",
        "period_start_date\u003dNone\n",
        "split\u003dNone\n",
        "#------------------------\n",
        "\n",
        "drawdown \u003d (100 - drawdown)/100\n",
        "drawdown_fwd_check /\u003d 100\n",
        "\n",
        "inactive_date_start \u003d pd.to_datetime(period_end_date) + relativedelta(months\u003d-inactive_period)\n",
        "\n",
        "if match_type \u003d\u003d \u0027conversion\u0027:\n",
        "    df \u003d df[df[\u0027CUSTOMER_SOURCE_SYSTEM_CODE\u0027] \u003d\u003d \u0027TANDEM\u0027].copy()\n",
        "\n",
        "df \u003d df[df[\u0027REVENUE_DATE\u0027] \u003c\u003d period_end_date].copy()\n",
        "\n",
        "if period_start_date:\n",
        "    period_start_date \u003d pd.to_datetime(period_start_date)\n",
        "    df \u003d df[df[\u0027REVENUE_DATE\u0027] \u003e\u003d period_start_date].copy()\n",
        "\n",
        "all_account_ids \u003d list(df[\u0027CUSTOMER_ACCOUNT_ID\u0027].unique())\n",
        "\n",
        "if not split:\n",
        "    split\u003d1\n",
        "\n",
        "all_account_ids_n \u003d list(split_list(all_account_ids, split))\n",
        "\n",
        "drop_df \u003d pd.DataFrame()\n",
        "\n",
        "for sublist in tqdm(all_account_ids_n):\n",
        "\n",
        "    dd_find \u003d df[df[\u0027CUSTOMER_ACCOUNT_ID\u0027].isin(sublist)].copy()\n",
        "\n",
        "    ## Find consistent customers\n",
        "    consistent_customers_dd \u003d find_consistent_customers(dd_find, consecutive\u003dconsistency)\n",
        "    if len(consistent_customers_dd) \u003d\u003d 0:\n",
        "        continue\n",
        "\n",
        "    dd_find \u003d dd_find[dd_find[\u0027CUSTOMER_ACCOUNT_ID\u0027].isin(consistent_customers_dd)].copy()\n",
        "\n",
        "    ## Add padding, find the n months average and compute drawdown indicator based on the rules\n",
        "    dd_find \u003d add_padding(dd_find, padding\u003dstatistics_period, last_date\u003dperiod_end_date)\n",
        "    dd_find \u003d find_average(dd_find, n\u003dstatistics_period)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Compute recipe outputs from inputs\n",
        "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
        "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
        "\n",
        "\n",
        "\n",
        "#CALCULATED_DRAW_DOWNS_df \u003d NAFCUSTOMER_C360_ACCOUNTS_df # For this sample code, simply copy input to output\n",
        "\n",
        "\n",
        "# Write recipe outputs\n",
        "#CALCULATED_DRAW_DOWNS \u003d dataiku.Dataset(\"CALCULATED_DRAW_DOWNS\")\n",
        "#CALCULATED_DRAW_DOWNS.write_with_schema(CALCULATED_DRAW_DOWNS_df)"
      ]
    }
  ]
}