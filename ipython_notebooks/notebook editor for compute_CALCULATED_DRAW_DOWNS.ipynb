{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-env_clc",
      "display_name": "Python (env env_clc)",
      "language": "python"
    },
    "associatedRecipe": "compute_CALCULATED_DRAW_DOWNS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "Daniel.Vandermeer"
      },
      "lastModifiedOn": 1665593021198
    },
    "creator": "Daniel.Vandermeer",
    "createdOn": 1665593021198,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "Daniel.Vandermeer"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\nimport pickle\nfrom dateutil.relativedelta import relativedelta\nimport gc\nfrom re import finditer\n\n## Find DD DU\nfrom helper import preprocess_data\nfrom patterns import find_drawdowns, find_drawups\n\n## MATCHING\nimport name_matching\nfrom name_matching import name_match\nimport transaction_matching\nfrom transaction_matching import transaction_match\n\n## CONSOLIDATION\nfrom consolidation import combine_matches, consolidate_matches, find_attritions, find_new_accounts, get_attrition_status, get_new_account_status"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "start_date \u003d dataiku.get_custom_variables()[\u0027start_date\u0027]\nend_date \u003d dataiku.get_custom_variables()[\u0027end_date\u0027]\n\nconsistency \u003d int(dataiku.get_custom_variables()[\u0027consistency\u0027])\ndrawdown_period_average \u003d int(dataiku.get_custom_variables()[\u0027drawdown_period_average\u0027])\ndrawdown \u003d int(dataiku.get_custom_variables()[\u0027drawdown\u0027])\ndrawdown_fwd_check \u003d int(dataiku.get_custom_variables()[\u0027drawdown_fwd_check\u0027])\ndrawdown_lookback_period \u003d int(dataiku.get_custom_variables()[\u0027drawdown_lookback_period\u0027])\ndrawup_lookfwd_period \u003d int(dataiku.get_custom_variables()[\u0027drawup_lookfwd_period\u0027])\nstatistics_period \u003d int(dataiku.get_custom_variables()[\u0027statistics_period\u0027])\ninactive_period \u003d int(dataiku.get_custom_variables()[\u0027inactive_period\u0027])\n\n## MATCHING VARIABLES\nmonth_diff_h \u003d int(dataiku.get_custom_variables()[\u0027month_diff_h\u0027])\nmonth_diff_l \u003d int(dataiku.get_custom_variables()[\u0027month_diff_l\u0027])\nsd_mul \u003d int(dataiku.get_custom_variables()[\u0027sd_mul\u0027])\nmax_city_distance \u003d int(dataiku.get_custom_variables()[\u0027max_city_distance\u0027])\nthreshold_score_step1 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step1\u0027])\nthreshold_score_step2 \u003d int(dataiku.get_custom_variables()[\u0027threshold_score_step2\u0027])\n\n## RUN TYPE\nrun \u003d dataiku.get_custom_variables()[\u0027run_type\u0027]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def date_tz_naive(pd_s):\n    return pd.to_datetime(pd_s).apply(lambda x:x.tz_localize(None))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nNAFCUSTOMER_C360_ACCOUNTS \u003d dataiku.Dataset(\"NAFCUSTOMER_C360_ACCOUNTS\")\nNAFCUSTOMER_C360_ACCOUNTS_df \u003d NAFCUSTOMER_C360_ACCOUNTS.get_dataframe()\nprint(len(NAFCUSTOMER_C360_ACCOUNTS_df))\n\nNAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED \u003d dataiku.Dataset(\"NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED\")\nNAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED.get_dataframe()\nprint(len(NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v \u003d NAFCUSTOMER_REVENUE_BY_CUSTOMER_LIMITED_df\n\nprint(len(df_v))\ndf_v[\u0027REVENUE_DATE\u0027] \u003d df_v.REVENUE_MONTH.astype(str) + \"/01/\" + df_v.REVENUE_YEAR.astype(str)\ndf_v[\u0027REVENUE_DATE\u0027] \u003d date_tz_naive(df_v[\u0027REVENUE_DATE\u0027])\nprint(len(df_v))\ndf_v.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(len(df_v))\ndf_v \u003d df_v[df_v[\u0027REVENUE_DATE\u0027].between(pd.to_datetime(start_date), pd.to_datetime(end_date))].copy()\ndf_v \u003d df_v.dropna(subset\u003d[\u0027CUSTOMER_ACCOUNT_ID\u0027])\ndf_v \u003d df_v[df_v[\u0027CUSTOMER_SOURCE_SYSTEM_CODE\u0027].isin([\u0027TANDEM\u0027, \u0027SIEBEL\u0027])]\nprint(len(df_v))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027] \u003d df_v[\u0027CUSTOMER_ACCOUNT_ID\u0027].astype(\u0027int64\u0027)\ndf_v[\u0027REVENUE_DATE\u0027] \u003d pd.to_datetime(df_v[\u0027REVENUE_DATE\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "states \u003d list(df_v[\u0027ACCOUNT_STATE\u0027].unique())\nstates_dict \u003d {s:s.upper() for s in states}"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v[\u0027ACCOUNT_STATE\u0027] \u003d df_v[\u0027ACCOUNT_STATE\u0027].map(states_dict)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## remove the unneccesary columns\nremove_cols\u003d[\u0027REVENUE_MONTH\u0027,\u0027REVENUE_YEAR\u0027, \u0027REVENUE_QUARTER\u0027]\ndf_v \u003d df_v.drop([x for x in remove_cols if x in df_v.columns], axis\u003d1)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v.sort_values([\u0027REVENUE_DATE\u0027], inplace\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "seen_accounts \u003d df_v[df_v[\u0027PURCHASE_GALLONS_QTY\u0027] \u003e 0].groupby([\u0027CUSTOMER_ACCOUNT_ID\u0027], as_index\u003dFalse)[[\u0027REVENUE_DATE\u0027]].first()\nseen_accounts[\u0027FIRST_DATE\u0027] \u003d seen_accounts[\u0027REVENUE_DATE\u0027] - pd.DateOffset(months\u003d1)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_v.REVENUE_DATE.value_counts(dropna\u003dFalse)\nprint(len(df_v))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom dateutil.relativedelta import relativedelta\nfrom helper import *\n\n#---------------------\n# input vars\ndf \u003d df_v\nperiod_end_date \u003d end_date\nmatch_type \u003d \u0027program_flip\u0027\nperiod_start_date\u003dNone\nsplit\u003dNone\n#------------------------\n\ndrawdown \u003d (100 - drawdown)/100\ndrawdown_fwd_check /\u003d 100\n\ninactive_date_start \u003d pd.to_datetime(period_end_date) + relativedelta(months\u003d-inactive_period)\n\nif match_type \u003d\u003d \u0027conversion\u0027:\n    df \u003d df[df[\u0027CUSTOMER_SOURCE_SYSTEM_CODE\u0027] \u003d\u003d \u0027TANDEM\u0027].copy()\n\ndf \u003d df[df[\u0027REVENUE_DATE\u0027] \u003c\u003d period_end_date].copy()\n\nif period_start_date:\n    period_start_date \u003d pd.to_datetime(period_start_date)\n    df \u003d df[df[\u0027REVENUE_DATE\u0027] \u003e\u003d period_start_date].copy()\n\nall_account_ids \u003d list(df[\u0027CUSTOMER_ACCOUNT_ID\u0027].unique())\n\nif not split:\n    split\u003d1\n\nall_account_ids_n \u003d list(split_list(all_account_ids, split))\n\ndrop_df \u003d pd.DataFrame()\n\nfor sublist in tqdm(all_account_ids_n):\n\n    dd_find \u003d df[df[\u0027CUSTOMER_ACCOUNT_ID\u0027].isin(sublist)].copy()\n\n    ## Find consistent customers\n    consistent_customers_dd \u003d find_consistent_customers(dd_find, consecutive\u003dconsistency)\n    if len(consistent_customers_dd) \u003d\u003d 0:\n        continue\n\n    dd_find \u003d dd_find[dd_find[\u0027CUSTOMER_ACCOUNT_ID\u0027].isin(consistent_customers_dd)].copy()\n\n    ## Add padding, find the n months average and compute drawdown indicator based on the rules\n    dd_find \u003d add_padding(dd_find, padding\u003dstatistics_period, last_date\u003dperiod_end_date)\n    dd_find \u003d find_average(dd_find, n\u003dstatistics_period)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\n\n\n#CALCULATED_DRAW_DOWNS_df \u003d NAFCUSTOMER_C360_ACCOUNTS_df # For this sample code, simply copy input to output\n\n\n# Write recipe outputs\n#CALCULATED_DRAW_DOWNS \u003d dataiku.Dataset(\"CALCULATED_DRAW_DOWNS\")\n#CALCULATED_DRAW_DOWNS.write_with_schema(CALCULATED_DRAW_DOWNS_df)"
      ],
      "outputs": []
    }
  ]
}